{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO0qQ5YuIkP990KboyYnVJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steliosg23/PDS-A2/blob/main/Incidents_Augmentation_using_EleutherAI_gpt_neo_125M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/MyDrive/Data/incidents_train.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop the 'Unnamed: 0' column\n",
        "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "# Initialize a smaller free text generation model with explicit pad_token_id\n",
        "generator = pipeline(\n",
        "    'text-generation',\n",
        "    model='EleutherAI/gpt-neo-125M',  # Smaller model\n",
        "    max_length=200,\n",
        "    device=-1,  # Use CPU\n",
        "    pad_token_id=50256  # Explicitly set pad_token_id to prevent warning\n",
        ")\n",
        "\n",
        "# Function to augment a specific class with synthetic title and text\n",
        "def augment_class(data, column, class_label, n_samples):\n",
        "    class_samples = data[data[column] == class_label]\n",
        "    generated_samples = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        # Generate synthetic title\n",
        "        title_prompt = f\"Generate a title for an incident related to {class_label} in the {column} category.\"\n",
        "        synthetic_title = generator(title_prompt, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "        # Generate synthetic description\n",
        "        text_prompt = f\"Generate an incident description related to {class_label} in the {column} category.\"\n",
        "        synthetic_text = generator(text_prompt, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "        # Create new row with synthetic title and text\n",
        "        new_row = class_samples.iloc[0].copy()\n",
        "        new_row['title'] = synthetic_title\n",
        "        new_row['text'] = synthetic_text\n",
        "        new_row[column] = class_label\n",
        "        generated_samples.append(new_row)\n",
        "\n",
        "    return pd.DataFrame(generated_samples)\n",
        "\n",
        "# Define target columns and minimum samples per class\n",
        "target_columns = ['hazard-category', 'product-category', 'hazard', 'product']\n",
        "min_samples = 100  # Minimum desired samples per class\n",
        "\n",
        "# Augment classes for each target\n",
        "augmented_dataframes = []\n",
        "for target in target_columns:\n",
        "    class_counts = df[target].value_counts()\n",
        "    for class_label, count in class_counts.items():\n",
        "        if count < min_samples:\n",
        "            n_to_generate = min_samples - count\n",
        "            augmented_df = augment_class(df, target, class_label, n_to_generate)\n",
        "            augmented_dataframes.append(augmented_df)\n",
        "\n",
        "# Combine the original and augmented datasets\n",
        "augmented_df = pd.concat([df] + augmented_dataframes, ignore_index=True)\n",
        "\n",
        "# Save the augmented dataset\n",
        "output_path = '/content/drive/MyDrive/Data/augmented_incidents.csv'\n",
        "augmented_df.to_csv(output_path, index=False)\n"
      ],
      "metadata": {
        "id": "ITXWQt_d96M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jCnJKyEOJB6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}