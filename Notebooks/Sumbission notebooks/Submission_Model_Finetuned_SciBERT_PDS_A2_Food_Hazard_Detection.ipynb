{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/steliosg23/PDS-A2/blob/main/SUBMISSION%20Finetuned%20PubMedBERT%20PDS%20A2%20Food%20Hazard%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIrEfVFOgZWa"
   },
   "source": [
    "## SUBMISSION WITH PRETRAINED SciBERT\n",
    "### Due to the 'product' class loss error consistently being stuck between 4.5 and 5, I decided to replace the pretrained BERT model with SciBERT to improve performance.\n",
    "The training corpus was papers taken from Semantic Scholar. Corpus size is 1.14M papers, 3.1B tokens. Team used the full text of the papers in training, not just abstracts.\n",
    "([1903.10676](https://arxiv.org/abs/1903.10676))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up2bFjloyvaZ"
   },
   "source": [
    "# Install necessary packages and import libraries\n",
    "This section includes all the necessary imports for data manipulation, model training, and evaluation.\n",
    "It also imports libraries for handling tokenization, model configuration, and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ySpgDtU5ywQM"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from shutil import make_archive\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIYvD2xxyzL8"
   },
   "source": [
    "# Mount Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiM_6Z68yxJ6",
    "outputId": "80696a0d-72ba-49c7-ea56-6b9a9b73f29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2q92Do-y2W9"
   },
   "source": [
    "# Load and preview the training dataset\n",
    "The dataset containing incident reports is loaded from Google Drive.\n",
    "We remove any unnecessary columns like 'Unnamed: 0'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ncSsiInty1G9"
   },
   "outputs": [],
   "source": [
    "train_path = '/content/drive/MyDrive/Data/incidents_train.csv'\n",
    "df = pd.read_csv(train_path)\n",
    "df = df.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDS28Uk-zNPU"
   },
   "source": [
    "# Define a function to clean text data\n",
    "This function removes special characters, converts text to lowercase, and strips extra whitespace.\n",
    "It is essential to clean the text data for better model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DxuoSFEUy3rX"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = ' '.join(text.split())  # Remove extra spaces\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBAtfWSgzROT"
   },
   "source": [
    "# Clean the text data and load the tokenizer\n",
    "We apply the `clean_text` function to clean the 'text' column of the dataset.\n",
    "Then, we initialize the PubMedBERT tokenizer to prepare for tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0Gy9-3ezQVb",
    "outputId": "a511bdc6-f31c-4624-93bf-0855358b4d5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer for the PubMedBERT model, specifically fine-tuned for biomedical text\n",
    "model_name=\"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Apply the text cleaning function to the 'text' column in the DataFrame\n",
    "# This function will preprocess each text entry by removing unwanted characters, stopwords, etc.\n",
    "df['text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6hPAUKozWMw"
   },
   "source": [
    "# Define features and targets for classification tasks\n",
    "We specify the input features like date and country and set the classification targets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kvkxIfuvzU3Z"
   },
   "outputs": [],
   "source": [
    "# Define the features for the model, which include the year, month, day, and country information\n",
    "features = ['year', 'month', 'day', 'country']\n",
    "\n",
    "# Define the target variables for Subtask 1, which are the hazard-category and product-category\n",
    "targets_subtask1 = ['hazard-category', 'product-category']\n",
    "\n",
    "\n",
    "# Define the target variables for Subtask 2, which are hazard and product\n",
    "# Add other targets if necessary depending on the task\n",
    "targets_subtask2 = ['hazard', 'product']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hn5LTh_zjI2"
   },
   "source": [
    "# Encode target labels\n",
    "For classification, target labels need to be encoded as numeric values.\n",
    "We use `LabelEncoder` to convert categorical labels into integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8Wd6N94wziDV"
   },
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store label encoders for each target\n",
    "label_encoders = {}\n",
    "\n",
    "# Iterate over both sets of targets (Subtask 1 and Subtask 2)\n",
    "for target in targets_subtask1 + targets_subtask2:\n",
    "    # Initialize a LabelEncoder for each target\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Transform the target column values into numeric labels and update the DataFrame\n",
    "    df[target] = le.fit_transform(df[target])\n",
    "\n",
    "    # Store the fitted LabelEncoder in the dictionary for future use (e.g., inverse transformation)\n",
    "    label_encoders[target] = le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdnDHxmlzpCm"
   },
   "source": [
    "# Define a custom PyTorch dataset for text classification\n",
    "This dataset class will handle text tokenization and label processing.\n",
    "It ensures the text is properly encoded, padded, and truncated to a fixed length for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wkzzsS2Gzk9L"
   },
   "outputs": [],
   "source": [
    "# Define a custom Dataset class for text data\n",
    "class TextDataset(Dataset):\n",
    "    # Initialize the dataset with texts, labels, tokenizer, and maximum sequence length\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts  # List of input texts\n",
    "        self.labels = labels  # List of corresponding labels\n",
    "        self.tokenizer = tokenizer  # Tokenizer for encoding the text\n",
    "        self.max_len = max_len  # Maximum length for padding/truncation\n",
    "\n",
    "    # Define the length of the dataset (number of samples)\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    # Define how to retrieve a single item from the dataset\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])  # Get the text for the given index\n",
    "        label = self.labels[item]  # Get the label for the given index\n",
    "\n",
    "        # Use the tokenizer to encode the text (add special tokens, padding, truncation)\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add special tokens (e.g., [CLS], [SEP])\n",
    "            max_length=self.max_len,  # Limit the sequence length\n",
    "            padding='max_length',  # Pad sequences to max_length\n",
    "            truncation=True,  # Truncate longer sequences\n",
    "            return_tensors='pt'  # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Return a dictionary with input_ids, attention_mask, and label\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),  # Flatten the tensor\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),  # Flatten the attention mask\n",
    "            'label': torch.tensor(label, dtype=torch.long)  # Convert label to a tensor\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbkXM6pdzsmb"
   },
   "source": [
    "# Split the data into training and testing sets\n",
    "We split the dataset into training and testing sets for each target.\n",
    "This ensures that the model is trained on one set and evaluated on a separate, unseen set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dSuyInwzzrYc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a function to prepare data for model training and testing (no validation)\n",
    "def prepare_data(text_column):\n",
    "    # Extract features and text column from the DataFrame\n",
    "    X = df[features + [text_column]]  # Features include specified columns plus the text column\n",
    "    # Extract target variables for Subtask 1 and Subtask 2\n",
    "    y_subtask1 = df[targets_subtask1]\n",
    "    y_subtask2 = df[targets_subtask2]\n",
    "\n",
    "    # Initialize a dictionary to store data splits for each target\n",
    "    data_splits = {}\n",
    "\n",
    "    # Iterate over both sets of target variables (Subtask 1 and Subtask 2)\n",
    "    for target in targets_subtask1 + targets_subtask2:\n",
    "        # Split the data into training (90%) and testing (10%) sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, df[target], test_size=0.1, random_state=42\n",
    "        )\n",
    "\n",
    "        # Reset the indices for the train and test sets\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "        # Store the splits for the current target in the dictionary\n",
    "        data_splits[target] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Return the dictionary containing data splits for each target\n",
    "    return data_splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFhciBb6zvnJ"
   },
   "source": [
    "# Prepare the data splits for text-based tasks\n",
    "We apply the `prepare_data` function specifically for text tasks and save the splits for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y7o-Gi7vzuZR"
   },
   "outputs": [],
   "source": [
    "# Prepare the data splits for the 'text' column using the prepare_data function\n",
    "text_splits = prepare_data('text')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEJgXRNIzybH"
   },
   "source": [
    "# Set model configuration and define the device\n",
    "Here, we configure key parameters for training like maximum sequence length, batch size, and learning rate.\n",
    "We also determine whether to use GPU or CPU for training based on availability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TetF1XIzxU8",
    "outputId": "b6cedd3b-8eb5-43b2-8f0e-b9ee7e6ef1ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define configuration settings for the model training\n",
    "config = {\n",
    "    'max_len': 256,  # Maximum sequence length for input texts\n",
    "    'batch_size': 16,  # Batch size for training\n",
    "    'learning_rate': 5e-5,  # Learning rate for the optimizer\n",
    "    'epochs': 100,  # Increased number of training epochs\n",
    "    'model_name': model_name  # Pre-trained model to use\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Determine the device to use for training (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u22f8LM6z26I"
   },
   "source": [
    "# Training Function Explanation\n",
    "\n",
    "## Overview\n",
    "The `train_and_evaluate_bert` function in the submission notebook has been redesigned with key enhancements to improve the training process compared to the benchmark notebooks. These changes include better handling of class imbalance, task-specific adaptations, and improved evaluation metrics, ensuring more robust performance and generalization.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features in the Submission Notebook\n",
    "\n",
    "### 1. **Task-Specific Adaptation**\n",
    "- Automatically determines the number of classes (`num_labels`) for each task based on the dataset.\n",
    "- Saves task-specific label encoders, models, and tokenizers for easy reuse and deployment.\n",
    "\n",
    "### 2. **Macro F1-Score Evaluation**\n",
    "- **Change Implemented:** The evaluation metric has been updated to use **macro F1-score** instead of weighted F1-score to better reflect the model's performance across all classes, regardless of class distribution.\n",
    "- Ensures fair evaluation, especially for tasks with imbalanced datasets.\n",
    "\n",
    "### 3. **Efficient Training with Early Stopping**\n",
    "- Introduces early stopping to halt training when validation loss stops improving, preventing overfitting and saving computational resources.\n",
    "\n",
    "### 4. **Learning Rate Scheduling**\n",
    "- Uses `ReduceLROnPlateau` to adjust the learning rate dynamically based on validation loss, ensuring smoother convergence.\n",
    "\n",
    "### 5. **Enhanced Model Saving**\n",
    "- Saves the best-performing model weights, tokenizer, and task-specific label encoders for deployment or further experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparison with Benchmark Notebooks\n",
    "- **Improved Metric Selection:** The switch to **macro F1-score** ensures fairer performance evaluation across all classes compared to the weighted F1-score used in the benchmark notebooks.\n",
    "- **Better Training Pipeline:** Includes features like class weights, early stopping, and learning rate scheduling, which may not be fully utilized in the benchmark implementations.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "The submission notebook incorporates several improvements, including a shift to macro F1-score and a more refined training pipeline, to provide better and fairer results compared to the benchmark notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CGK109f4hgK"
   },
   "source": [
    "#### Added AdamW instead of Adam\n",
    "AdamW is an improvement over Adam as it decouples weight decay from the gradient update, providing better regularization and performance, especially for transformer-based models.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "imN-jiGRz1xV",
    "outputId": "5af9bf99-4c7e-4192-e122-815614cef127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for task: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 286/286 [00:54<00:00,  5.26it/s, loss=0.0384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 1: 0.5506707068428501\n",
      "Learning rate after epoch 1: 5e-05\n",
      "New best model found. Saving at epoch 1.\n",
      "Epoch 2/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.0729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 2: 0.2507917199094969\n",
      "Learning rate after epoch 2: 5e-05\n",
      "New best model found. Saving at epoch 2.\n",
      "Epoch 3/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 3: 0.1845696043366423\n",
      "Learning rate after epoch 3: 5e-05\n",
      "New best model found. Saving at epoch 3.\n",
      "Epoch 4/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.0449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 4: 0.1550734194249592\n",
      "Learning rate after epoch 4: 5e-05\n",
      "New best model found. Saving at epoch 4.\n",
      "Epoch 5/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 5: 0.12192617113851792\n",
      "Learning rate after epoch 5: 5e-05\n",
      "New best model found. Saving at epoch 5.\n",
      "Epoch 6/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 6: 0.11942777059926697\n",
      "Learning rate after epoch 6: 5e-05\n",
      "New best model found. Saving at epoch 6.\n",
      "Epoch 7/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 7: 0.08184327960903333\n",
      "Learning rate after epoch 7: 5e-05\n",
      "New best model found. Saving at epoch 7.\n",
      "Epoch 8/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 8: 0.08074827492969774\n",
      "Learning rate after epoch 8: 5e-05\n",
      "New best model found. Saving at epoch 8.\n",
      "Epoch 9/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.0197]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 9: 0.07274087309313065\n",
      "Learning rate after epoch 9: 5e-05\n",
      "New best model found. Saving at epoch 9.\n",
      "Epoch 10/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 10: 0.07131334409521489\n",
      "Learning rate after epoch 10: 5e-05\n",
      "New best model found. Saving at epoch 10.\n",
      "Epoch 11/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.00949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 11: 0.06014495298154066\n",
      "Learning rate after epoch 11: 5e-05\n",
      "New best model found. Saving at epoch 11.\n",
      "Epoch 12/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.00342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 12: 0.04285775227989135\n",
      "Learning rate after epoch 12: 5e-05\n",
      "New best model found. Saving at epoch 12.\n",
      "Epoch 13/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.0163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 13: 0.05706030221849719\n",
      "Learning rate after epoch 13: 5e-05\n",
      "Epoch 14/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 14: 0.0492229862549746\n",
      "Learning rate after epoch 14: 5e-05\n",
      "Epoch 15/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 15: 0.04892703846859798\n",
      "Learning rate after epoch 15: 5e-05\n",
      "Epoch 16/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 16: 0.03599766239571105\n",
      "Learning rate after epoch 16: 5e-05\n",
      "New best model found. Saving at epoch 16.\n",
      "Epoch 17/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 17: 0.024528141825669935\n",
      "Learning rate after epoch 17: 5e-05\n",
      "New best model found. Saving at epoch 17.\n",
      "Epoch 18/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.0127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 18: 0.02735681315874632\n",
      "Learning rate after epoch 18: 5e-05\n",
      "Epoch 19/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 19: 0.06397612790892168\n",
      "Learning rate after epoch 19: 5e-05\n",
      "Epoch 20/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 20: 0.04421753063390904\n",
      "Learning rate after epoch 20: 5e-05\n",
      "Epoch 21/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 21: 0.029761920901262885\n",
      "Learning rate after epoch 21: 5e-05\n",
      "Epoch 22/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 22: 0.00793459004245477\n",
      "Learning rate after epoch 22: 5e-06\n",
      "New best model found. Saving at epoch 22.\n",
      "Epoch 23/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 23: 0.004056408689552722\n",
      "Learning rate after epoch 23: 5e-06\n",
      "New best model found. Saving at epoch 23.\n",
      "Epoch 24/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 24: 0.003755548002786114\n",
      "Learning rate after epoch 24: 5e-06\n",
      "New best model found. Saving at epoch 24.\n",
      "Epoch 25/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 25: 0.0027411983129031095\n",
      "Learning rate after epoch 25: 5e-06\n",
      "New best model found. Saving at epoch 25.\n",
      "Epoch 26/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.00149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 26: 0.002844827316605349\n",
      "Learning rate after epoch 26: 5e-06\n",
      "Epoch 27/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 27: 0.001949297229619371\n",
      "Learning rate after epoch 27: 5e-06\n",
      "New best model found. Saving at epoch 27.\n",
      "Epoch 28/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.00108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 28: 0.0018652821988700988\n",
      "Learning rate after epoch 28: 5e-06\n",
      "New best model found. Saving at epoch 28.\n",
      "Epoch 29/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 29: 0.002218923966503715\n",
      "Learning rate after epoch 29: 5e-06\n",
      "Epoch 30/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.000663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 30: 0.0008900280714391607\n",
      "Learning rate after epoch 30: 5e-06\n",
      "New best model found. Saving at epoch 30.\n",
      "Epoch 31/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.000341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 31: 0.002335477304698613\n",
      "Learning rate after epoch 31: 5e-06\n",
      "Epoch 32/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 32: 0.0006079481532219211\n",
      "Learning rate after epoch 32: 5e-06\n",
      "New best model found. Saving at epoch 32.\n",
      "Epoch 33/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 33: 0.0005552881797026661\n",
      "Learning rate after epoch 33: 5e-06\n",
      "New best model found. Saving at epoch 33.\n",
      "Epoch 34/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 34: 0.0006694340307250866\n",
      "Learning rate after epoch 34: 5e-06\n",
      "Epoch 35/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.000482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 35: 0.0004250261675866835\n",
      "Learning rate after epoch 35: 5e-06\n",
      "New best model found. Saving at epoch 35.\n",
      "Epoch 36/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 36: 0.00042334097729412954\n",
      "Learning rate after epoch 36: 5e-06\n",
      "New best model found. Saving at epoch 36.\n",
      "Epoch 37/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 37: 0.0004999556179179556\n",
      "Learning rate after epoch 37: 5e-06\n",
      "Epoch 38/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 38: 0.0004320778975884391\n",
      "Learning rate after epoch 38: 5e-06\n",
      "Epoch 39/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 39: 0.0002911287160745783\n",
      "Learning rate after epoch 39: 5e-06\n",
      "New best model found. Saving at epoch 39.\n",
      "Epoch 40/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 40: 0.00027372091375633267\n",
      "Learning rate after epoch 40: 5e-06\n",
      "New best model found. Saving at epoch 40.\n",
      "Epoch 41/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 41: 0.00022407398951240697\n",
      "Learning rate after epoch 41: 5e-06\n",
      "New best model found. Saving at epoch 41.\n",
      "Epoch 42/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 42: 0.0001955737067358829\n",
      "Learning rate after epoch 42: 5e-06\n",
      "New best model found. Saving at epoch 42.\n",
      "Epoch 43/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 43: 0.00017839535698172527\n",
      "Learning rate after epoch 43: 5e-06\n",
      "New best model found. Saving at epoch 43.\n",
      "Epoch 44/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 44: 0.00016689552084263578\n",
      "Learning rate after epoch 44: 5e-06\n",
      "New best model found. Saving at epoch 44.\n",
      "Epoch 45/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 45: 0.00016211091247782066\n",
      "Learning rate after epoch 45: 5e-06\n",
      "New best model found. Saving at epoch 45.\n",
      "Epoch 46/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.0002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 46: 0.00014113673433120903\n",
      "Learning rate after epoch 46: 5e-06\n",
      "New best model found. Saving at epoch 46.\n",
      "Epoch 47/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=0.00013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 47: 0.00012225628722319868\n",
      "Learning rate after epoch 47: 5e-06\n",
      "New best model found. Saving at epoch 47.\n",
      "Epoch 48/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=0.000104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 48: 0.00011470730581228829\n",
      "Learning rate after epoch 48: 5e-06\n",
      "New best model found. Saving at epoch 48.\n",
      "Epoch 49/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=6.27e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 49: 0.00010337844273285904\n",
      "Learning rate after epoch 49: 5e-06\n",
      "New best model found. Saving at epoch 49.\n",
      "Epoch 50/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=7e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 50: 9.319326168510711e-05\n",
      "Learning rate after epoch 50: 5e-06\n",
      "New best model found. Saving at epoch 50.\n",
      "Epoch 51/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=5.67e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 51: 8.147791191044922e-05\n",
      "Learning rate after epoch 51: 5e-06\n",
      "New best model found. Saving at epoch 51.\n",
      "Epoch 52/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=6.53e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 52: 7.691088693673964e-05\n",
      "Learning rate after epoch 52: 5e-06\n",
      "New best model found. Saving at epoch 52.\n",
      "Epoch 53/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=7.05e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 53: 6.814646069876282e-05\n",
      "Learning rate after epoch 53: 5e-06\n",
      "New best model found. Saving at epoch 53.\n",
      "Epoch 54/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=6.58e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 54: 6.270116883551074e-05\n",
      "Learning rate after epoch 54: 5e-06\n",
      "New best model found. Saving at epoch 54.\n",
      "Epoch 55/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=3.72e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 55: 5.436877517832135e-05\n",
      "Learning rate after epoch 55: 5e-06\n",
      "New best model found. Saving at epoch 55.\n",
      "Epoch 56/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=3.75e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 56: 5.656210309912335e-05\n",
      "Learning rate after epoch 56: 5e-06\n",
      "Epoch 57/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=2.65e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 57: 4.513692467069861e-05\n",
      "Learning rate after epoch 57: 5e-06\n",
      "New best model found. Saving at epoch 57.\n",
      "Epoch 58/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=3.23e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 58: 4.084309027469196e-05\n",
      "Learning rate after epoch 58: 5e-06\n",
      "New best model found. Saving at epoch 58.\n",
      "Epoch 59/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=2.51e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 59: 3.717754681382395e-05\n",
      "Learning rate after epoch 59: 5e-06\n",
      "New best model found. Saving at epoch 59.\n",
      "Epoch 60/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=2.56e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 60: 3.3436716221076746e-05\n",
      "Learning rate after epoch 60: 5e-06\n",
      "New best model found. Saving at epoch 60.\n",
      "Epoch 61/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=2.16e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 61: 3.053969061880338e-05\n",
      "Learning rate after epoch 61: 5e-06\n",
      "New best model found. Saving at epoch 61.\n",
      "Epoch 62/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=3.17e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 62: 2.9287820977318204e-05\n",
      "Learning rate after epoch 62: 5e-06\n",
      "New best model found. Saving at epoch 62.\n",
      "Epoch 63/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1.39e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 63: 2.4208576222873533e-05\n",
      "Learning rate after epoch 63: 5e-06\n",
      "New best model found. Saving at epoch 63.\n",
      "Epoch 64/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1.52e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 64: 2.20181725787618e-05\n",
      "Learning rate after epoch 64: 5e-06\n",
      "New best model found. Saving at epoch 64.\n",
      "Epoch 65/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=3.56e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 65: 2.0093901181556698e-05\n",
      "Learning rate after epoch 65: 5e-06\n",
      "New best model found. Saving at epoch 65.\n",
      "Epoch 66/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=9.04e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 66: 1.8137192668533074e-05\n",
      "Learning rate after epoch 66: 5e-06\n",
      "New best model found. Saving at epoch 66.\n",
      "Epoch 67/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1.42e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 67: 1.603443055265651e-05\n",
      "Learning rate after epoch 67: 5e-06\n",
      "New best model found. Saving at epoch 67.\n",
      "Epoch 68/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1.46e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 68: 1.446771939395053e-05\n",
      "Learning rate after epoch 68: 5e-06\n",
      "New best model found. Saving at epoch 68.\n",
      "Epoch 69/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1.16e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 69: 1.3003372692332483e-05\n",
      "Learning rate after epoch 69: 5e-06\n",
      "New best model found. Saving at epoch 69.\n",
      "Epoch 70/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1.66e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 70: 1.1861603049758493e-05\n",
      "Learning rate after epoch 70: 5e-06\n",
      "New best model found. Saving at epoch 70.\n",
      "Epoch 71/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71: 100%|██████████| 286/286 [00:53<00:00,  5.38it/s, loss=7.35e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 71: 1.107372327169287e-05\n",
      "Learning rate after epoch 71: 5e-06\n",
      "New best model found. Saving at epoch 71.\n",
      "Epoch 72/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 72: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=5.05e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 72: 9.429786100586139e-06\n",
      "Learning rate after epoch 72: 5e-06\n",
      "New best model found. Saving at epoch 72.\n",
      "Epoch 73/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=7.97e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 73: 0.0015602055318563576\n",
      "Learning rate after epoch 73: 5e-06\n",
      "Epoch 74/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=6.53e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 74: 1.1796845181767433e-05\n",
      "Learning rate after epoch 74: 5e-06\n",
      "Epoch 75/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 75: 0.0030563820215341116\n",
      "Learning rate after epoch 75: 5e-06\n",
      "Epoch 76/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=9.16e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 76: 1.2744147286523346e-05\n",
      "Learning rate after epoch 76: 5e-06\n",
      "Epoch 77/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 77: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=7.66e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 77: 1.2941569396586405e-05\n",
      "Learning rate after epoch 77: 5.000000000000001e-07\n",
      "Epoch 78/100 - Training: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=6.13e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 78: 3.128013429034524e-05\n",
      "Learning rate after epoch 78: 5.000000000000001e-07\n",
      "Early stopping triggered!\n",
      "Saving the best model from epoch 72.\n",
      "Evaluating model for task: hazard-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:02<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score for hazard-category: 0.8176909854072747\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "                     allergens       0.97      0.98      0.98       188\n",
      "                    biological       0.99      0.99      0.99       171\n",
      "                      chemical       0.92      0.97      0.94        35\n",
      "food additives and flavourings       1.00      0.20      0.33         5\n",
      "                foreign bodies       0.98      1.00      0.99        58\n",
      "                         fraud       0.79      0.79      0.79        28\n",
      "                     migration       1.00      1.00      1.00         1\n",
      "          organoleptic aspects       0.50      1.00      0.67         3\n",
      "                  other hazard       0.83      0.67      0.74        15\n",
      "              packaging defect       1.00      0.60      0.75         5\n",
      "\n",
      "                      accuracy                           0.95       509\n",
      "                     macro avg       0.90      0.82      0.82       509\n",
      "                  weighted avg       0.96      0.95      0.95       509\n",
      "\n",
      "Label Encoder for hazard-category saved.\n",
      "\n",
      "Starting training for task: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 286/286 [00:53<00:00,  5.37it/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 1: 1.8626904698101792\n",
      "Learning rate after epoch 1: 5e-05\n",
      "New best model found. Saving at epoch 1.\n",
      "Epoch 2/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 2: 1.030341590722124\n",
      "Learning rate after epoch 2: 5e-05\n",
      "New best model found. Saving at epoch 2.\n",
      "Epoch 3/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 3: 0.6681653124417042\n",
      "Learning rate after epoch 3: 5e-05\n",
      "New best model found. Saving at epoch 3.\n",
      "Epoch 4/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 4: 0.44227623632112584\n",
      "Learning rate after epoch 4: 5e-05\n",
      "New best model found. Saving at epoch 4.\n",
      "Epoch 5/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 5: 0.31131886952667387\n",
      "Learning rate after epoch 5: 5e-05\n",
      "New best model found. Saving at epoch 5.\n",
      "Epoch 6/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 6: 0.20390495080565968\n",
      "Learning rate after epoch 6: 5e-05\n",
      "New best model found. Saving at epoch 6.\n",
      "Epoch 7/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 7: 0.15971934330695264\n",
      "Learning rate after epoch 7: 5e-05\n",
      "New best model found. Saving at epoch 7.\n",
      "Epoch 8/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 8: 0.10982705317470212\n",
      "Learning rate after epoch 8: 5e-05\n",
      "New best model found. Saving at epoch 8.\n",
      "Epoch 9/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 9: 0.12519984147706806\n",
      "Learning rate after epoch 9: 5e-05\n",
      "Epoch 10/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 10: 0.10197683323379866\n",
      "Learning rate after epoch 10: 5e-05\n",
      "New best model found. Saving at epoch 10.\n",
      "Epoch 11/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 11: 0.1351453650863255\n",
      "Learning rate after epoch 11: 5e-05\n",
      "Epoch 12/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 12: 0.08518393176291919\n",
      "Learning rate after epoch 12: 5e-05\n",
      "New best model found. Saving at epoch 12.\n",
      "Epoch 13/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 13: 0.044769636043949845\n",
      "Learning rate after epoch 13: 5e-05\n",
      "New best model found. Saving at epoch 13.\n",
      "Epoch 14/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 14: 0.06985294389321918\n",
      "Learning rate after epoch 14: 5e-05\n",
      "Epoch 15/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 15: 0.0767114327803671\n",
      "Learning rate after epoch 15: 5e-05\n",
      "Epoch 16/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 16: 0.06533068143176501\n",
      "Learning rate after epoch 16: 5e-05\n",
      "Epoch 17/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 17: 0.0828037937424126\n",
      "Learning rate after epoch 17: 5e-05\n",
      "Epoch 18/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 18: 0.038034410987267515\n",
      "Learning rate after epoch 18: 5e-06\n",
      "New best model found. Saving at epoch 18.\n",
      "Epoch 19/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 19: 0.011497139182573484\n",
      "Learning rate after epoch 19: 5e-06\n",
      "New best model found. Saving at epoch 19.\n",
      "Epoch 20/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.00527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 20: 0.007384783038836936\n",
      "Learning rate after epoch 20: 5e-06\n",
      "New best model found. Saving at epoch 20.\n",
      "Epoch 21/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.00111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 21: 0.00581053296536357\n",
      "Learning rate after epoch 21: 5e-06\n",
      "New best model found. Saving at epoch 21.\n",
      "Epoch 22/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.00536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 22: 0.004410377283535012\n",
      "Learning rate after epoch 22: 5e-06\n",
      "New best model found. Saving at epoch 22.\n",
      "Epoch 23/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 23: 0.003643769803220875\n",
      "Learning rate after epoch 23: 5e-06\n",
      "New best model found. Saving at epoch 23.\n",
      "Epoch 24/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 24: 0.003229553880450036\n",
      "Learning rate after epoch 24: 5e-06\n",
      "New best model found. Saving at epoch 24.\n",
      "Epoch 25/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 25: 0.0031507365400267936\n",
      "Learning rate after epoch 25: 5e-06\n",
      "New best model found. Saving at epoch 25.\n",
      "Epoch 26/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 26: 0.0031720972593492743\n",
      "Learning rate after epoch 26: 5e-06\n",
      "Epoch 27/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 27: 0.003068257351381496\n",
      "Learning rate after epoch 27: 5e-06\n",
      "New best model found. Saving at epoch 27.\n",
      "Epoch 28/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 28: 0.003434324772601908\n",
      "Learning rate after epoch 28: 5e-06\n",
      "Epoch 29/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 29: 0.0031498248735279937\n",
      "Learning rate after epoch 29: 5e-06\n",
      "Epoch 30/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 30: 0.002988327156802822\n",
      "Learning rate after epoch 30: 5e-06\n",
      "New best model found. Saving at epoch 30.\n",
      "Epoch 31/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 31: 0.002819424547304699\n",
      "Learning rate after epoch 31: 5e-06\n",
      "New best model found. Saving at epoch 31.\n",
      "Epoch 32/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 32: 0.0032209258860748887\n",
      "Learning rate after epoch 32: 5e-06\n",
      "Epoch 33/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 33: 0.00290666771539767\n",
      "Learning rate after epoch 33: 5e-06\n",
      "Epoch 34/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 34: 0.0025891557355595335\n",
      "Learning rate after epoch 34: 5e-06\n",
      "New best model found. Saving at epoch 34.\n",
      "Epoch 35/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 35: 0.002551927077999156\n",
      "Learning rate after epoch 35: 5e-06\n",
      "New best model found. Saving at epoch 35.\n",
      "Epoch 36/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 36: 0.0025531629650361863\n",
      "Learning rate after epoch 36: 5e-06\n",
      "Epoch 37/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 37: 0.0025824757031949848\n",
      "Learning rate after epoch 37: 5e-06\n",
      "Epoch 38/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 38: 0.0023734871353229534\n",
      "Learning rate after epoch 38: 5e-06\n",
      "New best model found. Saving at epoch 38.\n",
      "Epoch 39/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 39: 0.0021715547078023697\n",
      "Learning rate after epoch 39: 5e-06\n",
      "New best model found. Saving at epoch 39.\n",
      "Epoch 40/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 40: 0.002196900940012151\n",
      "Learning rate after epoch 40: 5e-06\n",
      "Epoch 41/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 41: 0.0021825159776860596\n",
      "Learning rate after epoch 41: 5e-06\n",
      "Epoch 42/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 42: 0.0018940796564073446\n",
      "Learning rate after epoch 42: 5e-06\n",
      "New best model found. Saving at epoch 42.\n",
      "Epoch 43/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 43: 0.0022004920325992576\n",
      "Learning rate after epoch 43: 5e-06\n",
      "Epoch 44/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 44: 0.001893642334669659\n",
      "Learning rate after epoch 44: 5e-06\n",
      "New best model found. Saving at epoch 44.\n",
      "Epoch 45/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 45: 0.0019131315858538875\n",
      "Learning rate after epoch 45: 5e-06\n",
      "Epoch 46/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 46: 0.0018997941275250975\n",
      "Learning rate after epoch 46: 5e-06\n",
      "Epoch 47/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 47: 0.0018735418718050143\n",
      "Learning rate after epoch 47: 5e-06\n",
      "New best model found. Saving at epoch 47.\n",
      "Epoch 48/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 48: 0.0017634369007562501\n",
      "Learning rate after epoch 48: 5e-06\n",
      "New best model found. Saving at epoch 48.\n",
      "Epoch 49/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 49: 0.0018826606222961612\n",
      "Learning rate after epoch 49: 5e-06\n",
      "Epoch 50/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 50: 0.0051554378694856715\n",
      "Learning rate after epoch 50: 5e-06\n",
      "Epoch 51/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 51: 0.002122185135786739\n",
      "Learning rate after epoch 51: 5e-06\n",
      "Epoch 52/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 52: 0.003545593763917352\n",
      "Learning rate after epoch 52: 5e-06\n",
      "Epoch 53/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 53: 0.0013645130649336836\n",
      "Learning rate after epoch 53: 5.000000000000001e-07\n",
      "New best model found. Saving at epoch 53.\n",
      "Epoch 54/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 54: 0.001267639855598588\n",
      "Learning rate after epoch 54: 5.000000000000001e-07\n",
      "New best model found. Saving at epoch 54.\n",
      "Epoch 55/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 55: 0.001293113121957847\n",
      "Learning rate after epoch 55: 5.000000000000001e-07\n",
      "Epoch 56/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 56: 0.0011715837325129439\n",
      "Learning rate after epoch 56: 5.000000000000001e-07\n",
      "New best model found. Saving at epoch 56.\n",
      "Epoch 57/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 57: 0.001245172043839572\n",
      "Learning rate after epoch 57: 5.000000000000001e-07\n",
      "Epoch 58/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 58: 0.0011830251218003735\n",
      "Learning rate after epoch 58: 5.000000000000001e-07\n",
      "Epoch 59/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 59: 0.0012978409990196938\n",
      "Learning rate after epoch 59: 5.000000000000001e-07\n",
      "Epoch 60/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 60: 0.0012121122624569206\n",
      "Learning rate after epoch 60: 5.000000000000001e-07\n",
      "Epoch 61/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 61: 0.001219613016531127\n",
      "Learning rate after epoch 61: 5.000000000000001e-08\n",
      "Epoch 62/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 62: 0.001111500196215262\n",
      "Learning rate after epoch 62: 5.000000000000001e-08\n",
      "New best model found. Saving at epoch 62.\n",
      "Epoch 63/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 63: 0.001201468285127792\n",
      "Learning rate after epoch 63: 5.000000000000001e-08\n",
      "Epoch 64/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 64: 0.001315923127752991\n",
      "Learning rate after epoch 64: 5.000000000000001e-08\n",
      "Epoch 65/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 65: 0.001228997465506989\n",
      "Learning rate after epoch 65: 5.000000000000001e-08\n",
      "Epoch 66/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 66: 0.0015261993786270024\n",
      "Learning rate after epoch 66: 5.000000000000001e-08\n",
      "Epoch 67/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 67: 0.001279632066296319\n",
      "Learning rate after epoch 67: 5.000000000000002e-09\n",
      "Epoch 68/100 - Training: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 68: 0.0011529440960950231\n",
      "Learning rate after epoch 68: 5.000000000000002e-09\n",
      "Early stopping triggered!\n",
      "Saving the best model from epoch 62.\n",
      "Evaluating model for task: product-category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:02<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score for product-category: 0.716229391816495\n",
      "                                                   precision    recall  f1-score   support\n",
      "\n",
      "                              alcoholic beverages       0.33      0.50      0.40         2\n",
      "                      cereals and bakery products       0.69      0.81      0.75        54\n",
      "     cocoa and cocoa preparations, coffee and tea       0.71      0.93      0.81        29\n",
      "                                    confectionery       0.86      0.60      0.71        20\n",
      "dietetic foods, food supplements, fortified foods       0.75      0.82      0.78        11\n",
      "                                    fats and oils       1.00      0.67      0.80         3\n",
      "                                   feed materials       0.00      0.00      0.00         2\n",
      "                           food contact materials       1.00      1.00      1.00         1\n",
      "                            fruits and vegetables       0.79      0.79      0.79        56\n",
      "                                 herbs and spices       0.54      0.78      0.64         9\n",
      "                                ices and desserts       0.94      0.88      0.91        33\n",
      "                     meat, egg and dairy products       0.87      0.93      0.90       131\n",
      "                          non-alcoholic beverages       1.00      0.75      0.86        16\n",
      "                     nuts, nut products and seeds       0.97      0.76      0.85        37\n",
      "                       other food product / mixed       0.50      1.00      0.67         1\n",
      "                                         pet feed       0.75      1.00      0.86         3\n",
      "                       prepared dishes and snacks       0.55      0.35      0.43        51\n",
      "                                          seafood       0.87      0.96      0.92        28\n",
      "             soups, broths, sauces and condiments       0.62      0.62      0.62        21\n",
      "                                sugars and syrups       0.50      1.00      0.67         1\n",
      "\n",
      "                                         accuracy                           0.79       509\n",
      "                                        macro avg       0.71      0.76      0.72       509\n",
      "                                     weighted avg       0.79      0.79      0.78       509\n",
      "\n",
      "Label Encoder for product-category saved.\n",
      "\n",
      "Starting training for task: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=2.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 1: 2.462326313440616\n",
      "Learning rate after epoch 1: 5e-05\n",
      "New best model found. Saving at epoch 1.\n",
      "Epoch 2/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 2: 1.1104106225229644\n",
      "Learning rate after epoch 2: 5e-05\n",
      "New best model found. Saving at epoch 2.\n",
      "Epoch 3/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 3: 0.7780983397880425\n",
      "Learning rate after epoch 3: 5e-05\n",
      "New best model found. Saving at epoch 3.\n",
      "Epoch 4/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 4: 0.5792678424606582\n",
      "Learning rate after epoch 4: 5e-05\n",
      "New best model found. Saving at epoch 4.\n",
      "Epoch 5/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 5: 0.44966387635396493\n",
      "Learning rate after epoch 5: 5e-05\n",
      "New best model found. Saving at epoch 5.\n",
      "Epoch 6/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 6: 0.3780081460343583\n",
      "Learning rate after epoch 6: 5e-05\n",
      "New best model found. Saving at epoch 6.\n",
      "Epoch 7/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 7: 0.2907725438749144\n",
      "Learning rate after epoch 7: 5e-05\n",
      "New best model found. Saving at epoch 7.\n",
      "Epoch 8/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 8: 0.2269323114501117\n",
      "Learning rate after epoch 8: 5e-05\n",
      "New best model found. Saving at epoch 8.\n",
      "Epoch 9/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 9: 0.2590236435025618\n",
      "Learning rate after epoch 9: 5e-05\n",
      "Epoch 10/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 10: 0.19187348950458885\n",
      "Learning rate after epoch 10: 5e-05\n",
      "New best model found. Saving at epoch 10.\n",
      "Epoch 11/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 11: 0.1455356463255895\n",
      "Learning rate after epoch 11: 5e-05\n",
      "New best model found. Saving at epoch 11.\n",
      "Epoch 12/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 12: 0.12353203414737449\n",
      "Learning rate after epoch 12: 5e-05\n",
      "New best model found. Saving at epoch 12.\n",
      "Epoch 13/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 13: 0.12753049577944553\n",
      "Learning rate after epoch 13: 5e-05\n",
      "Epoch 14/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 14: 0.13933675857977226\n",
      "Learning rate after epoch 14: 5e-05\n",
      "Epoch 15/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 15: 0.08114129501082316\n",
      "Learning rate after epoch 15: 5e-05\n",
      "New best model found. Saving at epoch 15.\n",
      "Epoch 16/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 16: 0.07542007766221162\n",
      "Learning rate after epoch 16: 5e-05\n",
      "New best model found. Saving at epoch 16.\n",
      "Epoch 17/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 17: 0.05343704714058814\n",
      "Learning rate after epoch 17: 5e-05\n",
      "New best model found. Saving at epoch 17.\n",
      "Epoch 18/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 18: 0.041599681554524995\n",
      "Learning rate after epoch 18: 5e-05\n",
      "New best model found. Saving at epoch 18.\n",
      "Epoch 19/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 19: 0.03264114047381115\n",
      "Learning rate after epoch 19: 5e-05\n",
      "New best model found. Saving at epoch 19.\n",
      "Epoch 20/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 20: 0.0490096663401651\n",
      "Learning rate after epoch 20: 5e-05\n",
      "Epoch 21/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 21: 0.08602603726777723\n",
      "Learning rate after epoch 21: 5e-05\n",
      "Epoch 22/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 22: 0.09944390232383332\n",
      "Learning rate after epoch 22: 5e-05\n",
      "Epoch 23/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 23: 0.06961287778250261\n",
      "Learning rate after epoch 23: 5e-05\n",
      "Epoch 24/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 24: 0.038354477105121666\n",
      "Learning rate after epoch 24: 5e-06\n",
      "Epoch 25/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 25: 0.014369118967666648\n",
      "Learning rate after epoch 25: 5e-06\n",
      "New best model found. Saving at epoch 25.\n",
      "Epoch 26/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 26: 0.010080435644213267\n",
      "Learning rate after epoch 26: 5e-06\n",
      "New best model found. Saving at epoch 26.\n",
      "Epoch 27/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 27: 0.008899119202702118\n",
      "Learning rate after epoch 27: 5e-06\n",
      "New best model found. Saving at epoch 27.\n",
      "Epoch 28/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 28: 0.008003135036735737\n",
      "Learning rate after epoch 28: 5e-06\n",
      "New best model found. Saving at epoch 28.\n",
      "Epoch 29/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 29: 0.0072566691738833395\n",
      "Learning rate after epoch 29: 5e-06\n",
      "New best model found. Saving at epoch 29.\n",
      "Epoch 30/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.00395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 30: 0.006461352994421275\n",
      "Learning rate after epoch 30: 5e-06\n",
      "New best model found. Saving at epoch 30.\n",
      "Epoch 31/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 31: 0.006782616702742041\n",
      "Learning rate after epoch 31: 5e-06\n",
      "Epoch 32/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 32: 0.005471910503481261\n",
      "Learning rate after epoch 32: 5e-06\n",
      "New best model found. Saving at epoch 32.\n",
      "Epoch 33/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 33: 0.005202467466616625\n",
      "Learning rate after epoch 33: 5e-06\n",
      "New best model found. Saving at epoch 33.\n",
      "Epoch 34/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 34: 0.0049174213788058556\n",
      "Learning rate after epoch 34: 5e-06\n",
      "New best model found. Saving at epoch 34.\n",
      "Epoch 35/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 35: 0.004219615378724802\n",
      "Learning rate after epoch 35: 5e-06\n",
      "New best model found. Saving at epoch 35.\n",
      "Epoch 36/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 36: 0.004562949656119726\n",
      "Learning rate after epoch 36: 5e-06\n",
      "Epoch 37/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 37: 0.005420009586048293\n",
      "Learning rate after epoch 37: 5e-06\n",
      "Epoch 38/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 38: 0.003937770414814985\n",
      "Learning rate after epoch 38: 5e-06\n",
      "New best model found. Saving at epoch 38.\n",
      "Epoch 39/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 39: 0.0038855758976350844\n",
      "Learning rate after epoch 39: 5e-06\n",
      "New best model found. Saving at epoch 39.\n",
      "Epoch 40/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 40: 0.004133059015339631\n",
      "Learning rate after epoch 40: 5e-06\n",
      "Epoch 41/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 41: 0.002836356665678583\n",
      "Learning rate after epoch 41: 5e-06\n",
      "New best model found. Saving at epoch 41.\n",
      "Epoch 42/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 42: 0.003110678045085625\n",
      "Learning rate after epoch 42: 5e-06\n",
      "Epoch 43/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 43: 0.0032473353103659656\n",
      "Learning rate after epoch 43: 5e-06\n",
      "Epoch 44/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 44: 0.002737711607258754\n",
      "Learning rate after epoch 44: 5e-06\n",
      "New best model found. Saving at epoch 44.\n",
      "Epoch 45/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 45: 0.003006008420391106\n",
      "Learning rate after epoch 45: 5e-06\n",
      "Epoch 46/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 46: 0.002491406578419183\n",
      "Learning rate after epoch 46: 5e-06\n",
      "New best model found. Saving at epoch 46.\n",
      "Epoch 47/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 47: 0.0023917281018998276\n",
      "Learning rate after epoch 47: 5e-06\n",
      "New best model found. Saving at epoch 47.\n",
      "Epoch 48/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 48: 0.002330839544391403\n",
      "Learning rate after epoch 48: 5e-06\n",
      "New best model found. Saving at epoch 48.\n",
      "Epoch 49/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 49: 0.002424304763004151\n",
      "Learning rate after epoch 49: 5e-06\n",
      "Epoch 50/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 50: 0.00223068659977582\n",
      "Learning rate after epoch 50: 5e-06\n",
      "New best model found. Saving at epoch 50.\n",
      "Epoch 51/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 51: 0.0021310726412078628\n",
      "Learning rate after epoch 51: 5e-06\n",
      "New best model found. Saving at epoch 51.\n",
      "Epoch 52/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.000588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 52: 0.002185431636055407\n",
      "Learning rate after epoch 52: 5e-06\n",
      "Epoch 53/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 53: 0.001888197776138981\n",
      "Learning rate after epoch 53: 5e-06\n",
      "New best model found. Saving at epoch 53.\n",
      "Epoch 54/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 54: 0.0020985736096867237\n",
      "Learning rate after epoch 54: 5e-06\n",
      "Epoch 55/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 55: 0.001840071902053522\n",
      "Learning rate after epoch 55: 5e-06\n",
      "New best model found. Saving at epoch 55.\n",
      "Epoch 56/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 56: 0.001767011557056868\n",
      "Learning rate after epoch 56: 5e-06\n",
      "New best model found. Saving at epoch 56.\n",
      "Epoch 57/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 57: 0.0016778941810968774\n",
      "Learning rate after epoch 57: 5e-06\n",
      "New best model found. Saving at epoch 57.\n",
      "Epoch 58/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 58: 0.001671930374817799\n",
      "Learning rate after epoch 58: 5e-06\n",
      "New best model found. Saving at epoch 58.\n",
      "Epoch 59/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 59: 0.0018363524350651925\n",
      "Learning rate after epoch 59: 5e-06\n",
      "Epoch 60/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 60: 0.0015483252874899565\n",
      "Learning rate after epoch 60: 5e-06\n",
      "New best model found. Saving at epoch 60.\n",
      "Epoch 61/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 61: 0.0015010563171030287\n",
      "Learning rate after epoch 61: 5e-06\n",
      "New best model found. Saving at epoch 61.\n",
      "Epoch 62/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 62: 0.0013233358443936925\n",
      "Learning rate after epoch 62: 5e-06\n",
      "New best model found. Saving at epoch 62.\n",
      "Epoch 63/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 63: 0.0012783714392988932\n",
      "Learning rate after epoch 63: 5e-06\n",
      "New best model found. Saving at epoch 63.\n",
      "Epoch 64/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 64: 0.0014056568137281315\n",
      "Learning rate after epoch 64: 5e-06\n",
      "Epoch 65/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 65: 0.0012084588287272035\n",
      "Learning rate after epoch 65: 5e-06\n",
      "New best model found. Saving at epoch 65.\n",
      "Epoch 66/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=7.71e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 66: 0.0014761718004999741\n",
      "Learning rate after epoch 66: 5e-06\n",
      "Epoch 67/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 67: 0.001367838881792109\n",
      "Learning rate after epoch 67: 5e-06\n",
      "Epoch 68/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.000265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 68: 0.0012259165579924266\n",
      "Learning rate after epoch 68: 5e-06\n",
      "Epoch 69/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=9.44e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 69: 0.003233361083275795\n",
      "Learning rate after epoch 69: 5e-06\n",
      "Epoch 70/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 70: 0.0011664266489247524\n",
      "Learning rate after epoch 70: 5.000000000000001e-07\n",
      "New best model found. Saving at epoch 70.\n",
      "Epoch 71/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 71: 0.0010796459002093244\n",
      "Learning rate after epoch 71: 5.000000000000001e-07\n",
      "New best model found. Saving at epoch 71.\n",
      "Epoch 72/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 72: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 72: 0.001009849338197773\n",
      "Learning rate after epoch 72: 5.000000000000001e-07\n",
      "New best model found. Saving at epoch 72.\n",
      "Epoch 73/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=8.86e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 73: 0.0011648420120357011\n",
      "Learning rate after epoch 73: 5.000000000000001e-07\n",
      "Epoch 74/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 74: 0.0010295450397947447\n",
      "Learning rate after epoch 74: 5.000000000000001e-07\n",
      "Epoch 75/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 75: 0.0009075117230333325\n",
      "Learning rate after epoch 75: 5.000000000000001e-07\n",
      "New best model found. Saving at epoch 75.\n",
      "Epoch 76/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 76: 0.0009079868159969411\n",
      "Learning rate after epoch 76: 5.000000000000001e-07\n",
      "Epoch 77/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 77: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.000374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 77: 0.0012123059669946698\n",
      "Learning rate after epoch 77: 5.000000000000001e-07\n",
      "Epoch 78/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.000282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 78: 0.0009965190450081658\n",
      "Learning rate after epoch 78: 5.000000000000001e-07\n",
      "Epoch 79/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 79: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 79: 0.001036879146506015\n",
      "Learning rate after epoch 79: 5.000000000000001e-07\n",
      "Epoch 80/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 80: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 80: 0.0010539658377402938\n",
      "Learning rate after epoch 80: 5.000000000000001e-08\n",
      "Epoch 81/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 81: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 81: 0.000899522396787949\n",
      "Learning rate after epoch 81: 5.000000000000001e-08\n",
      "New best model found. Saving at epoch 81.\n",
      "Epoch 82/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 82: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.000247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 82: 0.0008909833591864477\n",
      "Learning rate after epoch 82: 5.000000000000001e-08\n",
      "New best model found. Saving at epoch 82.\n",
      "Epoch 83/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 83: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.00047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 83: 0.0009634034095206453\n",
      "Learning rate after epoch 83: 5.000000000000001e-08\n",
      "Epoch 84/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 84: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.000328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 84: 0.0009988817494629005\n",
      "Learning rate after epoch 84: 5.000000000000001e-08\n",
      "Epoch 85/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 85: 0.0009641295091441989\n",
      "Learning rate after epoch 85: 5.000000000000001e-08\n",
      "Epoch 86/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 86: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 86: 0.0009239743724153979\n",
      "Learning rate after epoch 86: 5.000000000000001e-08\n",
      "Epoch 87/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 87: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.000337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 87: 0.0010105451989160417\n",
      "Learning rate after epoch 87: 5.000000000000002e-09\n",
      "Epoch 88/100 - Training: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 88: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.000217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 88: 0.0008982849159345953\n",
      "Learning rate after epoch 88: 5.000000000000002e-09\n",
      "Early stopping triggered!\n",
      "Saving the best model from epoch 82.\n",
      "Evaluating model for task: hazard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:02<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score for hazard: 0.5392380390659323\n",
      "                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                      Aflatoxin       1.00      1.00      1.00         2\n",
      "                                 abnormal smell       0.00      0.00      0.00         0\n",
      "                                      alkaloids       1.00      1.00      1.00         2\n",
      "                                      allergens       0.00      0.00      0.00         3\n",
      "                                         almond       0.67      1.00      0.80         4\n",
      "                                      amygdalin       0.00      0.00      0.00         1\n",
      "                           bad smell / off odor       0.00      0.00      0.00         1\n",
      "                                  bone fragment       1.00      1.00      1.00         1\n",
      "                                     brazil nut       1.00      1.00      1.00         1\n",
      "                              bulging packaging       1.00      0.50      0.67         2\n",
      "                                         cashew       1.00      0.80      0.89         5\n",
      "                    celery and products thereof       0.00      0.00      0.00         1\n",
      " cereals containing gluten and products thereof       0.77      1.00      0.87        17\n",
      "                                       chemical       0.00      0.00      0.00         1\n",
      "               chemical compound (high content)       0.50      1.00      0.67         1\n",
      "                          clostridium botulinum       1.00      1.00      1.00         3\n",
      "                                        coconut       0.00      0.00      0.00         1\n",
      "                        compositional deviation       0.00      0.00      0.00         1\n",
      "                                cronobacter spp       1.00      1.00      1.00         1\n",
      "               crustaceans and products thereof       1.00      1.00      1.00         1\n",
      "                    e 425 - konjac unauthorised       0.00      0.00      0.00         2\n",
      "                      eggs and products thereof       0.94      0.94      0.94        16\n",
      "                               escherichia coli       1.00      1.00      1.00        16\n",
      "                      fish and products thereof       1.00      1.00      1.00         5\n",
      "                                 foreign bodies       0.33      0.50      0.40         2\n",
      "                                 glass fragment       1.00      0.80      0.89        10\n",
      "                                       hazelnut       1.00      0.50      0.67         2\n",
      "                                   heavy metals       0.80      1.00      0.89         4\n",
      "                        high content of cyanide       0.50      1.00      0.67         1\n",
      "                            improper conditions       0.00      0.00      0.00         2\n",
      "                             improper packaging       0.00      0.00      0.00         1\n",
      "                             incorrect labeling       0.00      0.00      0.00         1\n",
      "                         incorrect use by dates       1.00      1.00      1.00         4\n",
      "                              inspection issues       0.50      0.43      0.46         7\n",
      "           insufficient labelling/documentation       0.00      0.00      0.00         0\n",
      "                       labelling/misdescription       1.00      1.00      1.00         3\n",
      "                         listeria monocytogenes       0.95      0.97      0.96        75\n",
      "                                   listeria spp       0.00      0.00      0.00         1\n",
      "                                 metal fragment       0.94      0.94      0.94        16\n",
      "                  microbiological contamination       1.00      0.50      0.67         2\n",
      "                      milk and products thereof       0.97      0.98      0.97        59\n",
      "                                 misdescription       0.20      1.00      0.33         1\n",
      "                                         moulds       1.00      1.00      1.00         1\n",
      "                   mustard and products thereof       1.00      0.80      0.89         5\n",
      "                                      norovirus       1.00      1.00      1.00         2\n",
      "                                           nuts       0.25      0.50      0.33         2\n",
      "                                          other       0.42      0.36      0.38        14\n",
      "                           other not classified       0.25      0.33      0.29         3\n",
      "          other not classified allergen hazards       0.00      0.00      0.00         0\n",
      "        other not classified biological hazards       0.00      0.00      0.00         1\n",
      "          other not classified chemical hazards       1.00      0.67      0.80         3\n",
      "other not classified hazards for foreign bodies       0.00      0.00      0.00         1\n",
      "                               packaging defect       0.67      1.00      0.80         2\n",
      "     paralytic shellfish poisoning (psp) toxins       0.00      0.00      0.00         1\n",
      "                            pathogenic bacteria       0.00      0.00      0.00         1\n",
      "                   peanuts and products thereof       0.96      0.96      0.96        24\n",
      "                                      pecan nut       1.00      1.00      1.00         3\n",
      "                                  pistachio nut       0.67      1.00      0.80         2\n",
      "                               plastic fragment       0.83      0.96      0.89        25\n",
      "               polycyclic aromatic hydrocarbons       1.00      1.00      1.00         1\n",
      "                            poor hygienic state       0.00      0.00      0.00         1\n",
      "                  poor or insufficient controls       1.00      0.50      0.67         2\n",
      "                                     processing       0.75      0.75      0.75         4\n",
      "               product category/characteristics       0.00      0.00      0.00         1\n",
      "                               rubber fragments       1.00      0.67      0.80         3\n",
      "                                     salmonella       0.95      0.94      0.95        66\n",
      "              sesame seeds and products thereof       1.00      1.00      1.00         5\n",
      "                  soybeans and products thereof       0.94      0.88      0.91        17\n",
      "                  specified risk material (srm)       0.00      0.00      0.00         1\n",
      "                                       spoilage       0.33      1.00      0.50         1\n",
      "                                 staphylococcus       1.00      1.00      1.00         1\n",
      "                                         stones       0.00      0.00      0.00         0\n",
      "                            sulphates/sulphites       0.00      0.00      0.00         2\n",
      "                                sulphur dioxide       1.00      0.67      0.80         3\n",
      "                  sulphur dioxide and sulphites       0.73      1.00      0.85        11\n",
      "                                      tampering       0.00      0.00      0.00         2\n",
      "                              taste disturbance       0.00      0.00      0.00         1\n",
      " too high content of tetrahydrocannabinol (THC)       1.00      1.00      1.00         1\n",
      "                                          toxin       1.00      1.00      1.00         5\n",
      "          unauthorised substance ethylene oxide       1.00      1.00      1.00         8\n",
      "              unauthorised substance sildenafil       0.00      0.00      0.00         0\n",
      "                            undeclared additive       0.00      0.00      0.00         1\n",
      "                    unfit for human consumption       0.00      0.00      0.00         0\n",
      "                                         walnut       1.00      0.67      0.80         3\n",
      "                                         yeasts       0.00      0.00      0.00         0\n",
      "\n",
      "                                       accuracy                           0.86       509\n",
      "                                      macro avg       0.55      0.56      0.54       509\n",
      "                                   weighted avg       0.85      0.86      0.85       509\n",
      "\n",
      "Label Encoder for hazard saved.\n",
      "\n",
      "Starting training for task: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=6.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 1: 6.392377518273734\n",
      "Learning rate after epoch 1: 5e-05\n",
      "New best model found. Saving at epoch 1.\n",
      "Epoch 2/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=5.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 2: 5.824019297019585\n",
      "Learning rate after epoch 2: 5e-05\n",
      "New best model found. Saving at epoch 2.\n",
      "Epoch 3/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=3.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 3: 4.998034811520077\n",
      "Learning rate after epoch 3: 5e-05\n",
      "New best model found. Saving at epoch 3.\n",
      "Epoch 4/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=3.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 4: 4.207855374663026\n",
      "Learning rate after epoch 4: 5e-05\n",
      "New best model found. Saving at epoch 4.\n",
      "Epoch 5/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=2.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 5: 3.5736406824805518\n",
      "Learning rate after epoch 5: 5e-05\n",
      "New best model found. Saving at epoch 5.\n",
      "Epoch 6/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=3.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 6: 3.016747960260698\n",
      "Learning rate after epoch 6: 5e-05\n",
      "New best model found. Saving at epoch 6.\n",
      "Epoch 7/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 7: 2.550866683046301\n",
      "Learning rate after epoch 7: 5e-05\n",
      "New best model found. Saving at epoch 7.\n",
      "Epoch 8/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=2.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 8: 2.129601059676884\n",
      "Learning rate after epoch 8: 5e-05\n",
      "New best model found. Saving at epoch 8.\n",
      "Epoch 9/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=1.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 9: 1.7500097180579925\n",
      "Learning rate after epoch 9: 5e-05\n",
      "New best model found. Saving at epoch 9.\n",
      "Epoch 10/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 10: 1.438056481468094\n",
      "Learning rate after epoch 10: 5e-05\n",
      "New best model found. Saving at epoch 10.\n",
      "Epoch 11/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 11: 1.1797327785850404\n",
      "Learning rate after epoch 11: 5e-05\n",
      "New best model found. Saving at epoch 11.\n",
      "Epoch 12/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 12: 0.9658477662743389\n",
      "Learning rate after epoch 12: 5e-05\n",
      "New best model found. Saving at epoch 12.\n",
      "Epoch 13/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 13: 0.7825408760536384\n",
      "Learning rate after epoch 13: 5e-05\n",
      "New best model found. Saving at epoch 13.\n",
      "Epoch 14/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 14: 0.6370046807492112\n",
      "Learning rate after epoch 14: 5e-05\n",
      "New best model found. Saving at epoch 14.\n",
      "Epoch 15/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 15: 0.5219707434957886\n",
      "Learning rate after epoch 15: 5e-05\n",
      "New best model found. Saving at epoch 15.\n",
      "Epoch 16/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 16: 0.43435175453762076\n",
      "Learning rate after epoch 16: 5e-05\n",
      "New best model found. Saving at epoch 16.\n",
      "Epoch 17/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 17: 0.34724811670350864\n",
      "Learning rate after epoch 17: 5e-05\n",
      "New best model found. Saving at epoch 17.\n",
      "Epoch 18/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 18: 0.26693523369104294\n",
      "Learning rate after epoch 18: 5e-05\n",
      "New best model found. Saving at epoch 18.\n",
      "Epoch 19/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 19: 0.21438699245609186\n",
      "Learning rate after epoch 19: 5e-05\n",
      "New best model found. Saving at epoch 19.\n",
      "Epoch 20/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 20: 0.17480976613876703\n",
      "Learning rate after epoch 20: 5e-05\n",
      "New best model found. Saving at epoch 20.\n",
      "Epoch 21/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 286/286 [00:53<00:00,  5.35it/s, loss=0.0681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 21: 0.13723686502894739\n",
      "Learning rate after epoch 21: 5e-05\n",
      "New best model found. Saving at epoch 21.\n",
      "Epoch 22/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.0337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 22: 0.11081610691662018\n",
      "Learning rate after epoch 22: 5e-05\n",
      "New best model found. Saving at epoch 22.\n",
      "Epoch 23/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 286/286 [00:53<00:00,  5.34it/s, loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 23: 0.09110218660345862\n",
      "Learning rate after epoch 23: 5e-05\n",
      "New best model found. Saving at epoch 23.\n",
      "Epoch 24/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 24: 0.07200408315650754\n",
      "Learning rate after epoch 24: 5e-05\n",
      "New best model found. Saving at epoch 24.\n",
      "Epoch 25/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 25: 0.06689203359916077\n",
      "Learning rate after epoch 25: 5e-05\n",
      "New best model found. Saving at epoch 25.\n",
      "Epoch 26/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 26: 0.24499353632278792\n",
      "Learning rate after epoch 26: 5e-05\n",
      "Epoch 27/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 27: 0.39848863828432307\n",
      "Learning rate after epoch 27: 5e-05\n",
      "Epoch 28/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 28: 0.1388991885538493\n",
      "Learning rate after epoch 28: 5e-05\n",
      "Epoch 29/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 29: 0.05929318538515249\n",
      "Learning rate after epoch 29: 5e-05\n",
      "New best model found. Saving at epoch 29.\n",
      "Epoch 30/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 30: 0.0370024858088187\n",
      "Learning rate after epoch 30: 5e-05\n",
      "New best model found. Saving at epoch 30.\n",
      "Epoch 31/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 31: 0.026920069225614407\n",
      "Learning rate after epoch 31: 5e-05\n",
      "New best model found. Saving at epoch 31.\n",
      "Epoch 32/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 32: 0.021536907592260807\n",
      "Learning rate after epoch 32: 5e-05\n",
      "New best model found. Saving at epoch 32.\n",
      "Epoch 33/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 33: 0.018711788130442164\n",
      "Learning rate after epoch 33: 5e-05\n",
      "New best model found. Saving at epoch 33.\n",
      "Epoch 34/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 34: 0.016534754714987183\n",
      "Learning rate after epoch 34: 5e-05\n",
      "New best model found. Saving at epoch 34.\n",
      "Epoch 35/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.00694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 35: 0.015941620215780095\n",
      "Learning rate after epoch 35: 5e-05\n",
      "New best model found. Saving at epoch 35.\n",
      "Epoch 36/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 36: 0.013574966519315551\n",
      "Learning rate after epoch 36: 5e-05\n",
      "New best model found. Saving at epoch 36.\n",
      "Epoch 37/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.0171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 37: 0.01272438963145747\n",
      "Learning rate after epoch 37: 5e-05\n",
      "New best model found. Saving at epoch 37.\n",
      "Epoch 38/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.0119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 38: 0.012195259050980628\n",
      "Learning rate after epoch 38: 5e-05\n",
      "New best model found. Saving at epoch 38.\n",
      "Epoch 39/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 39: 0.010919502933047243\n",
      "Learning rate after epoch 39: 5e-05\n",
      "New best model found. Saving at epoch 39.\n",
      "Epoch 40/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 40: 0.009550438089527425\n",
      "Learning rate after epoch 40: 5e-05\n",
      "New best model found. Saving at epoch 40.\n",
      "Epoch 41/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 41: 0.009597684272200233\n",
      "Learning rate after epoch 41: 5e-05\n",
      "Epoch 42/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 42: 0.00934644868936051\n",
      "Learning rate after epoch 42: 5e-05\n",
      "New best model found. Saving at epoch 42.\n",
      "Epoch 43/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 286/286 [00:53<00:00,  5.33it/s, loss=0.00616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 43: 0.007949908232638756\n",
      "Learning rate after epoch 43: 5e-05\n",
      "New best model found. Saving at epoch 43.\n",
      "Epoch 44/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 286/286 [00:53<00:00,  5.36it/s, loss=0.00437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 44: 0.008448855774770198\n",
      "Learning rate after epoch 44: 5e-05\n",
      "Epoch 45/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 45: 0.05115191925356125\n",
      "Learning rate after epoch 45: 5e-05\n",
      "Epoch 46/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.0428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 46: 0.4668416811114216\n",
      "Learning rate after epoch 46: 5e-05\n",
      "Epoch 47/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.0265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 47: 0.10717448320278859\n",
      "Learning rate after epoch 47: 5e-05\n",
      "Epoch 48/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 286/286 [00:53<00:00,  5.31it/s, loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 48: 0.03635844247663146\n",
      "Learning rate after epoch 48: 5e-06\n",
      "Epoch 49/100 - Training: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 286/286 [00:53<00:00,  5.32it/s, loss=0.00833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss after Epoch 49: 0.019869982268192345\n",
      "Learning rate after epoch 49: 5e-06\n",
      "Early stopping triggered!\n",
      "Saving the best model from epoch 43.\n",
      "Evaluating model for task: product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [00:02<00:00, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score for product: 0.26950384280916106\n",
      "                                                         precision    recall  f1-score   support\n",
      "\n",
      "                                 Catfishes (freshwater)       1.00      0.67      0.80         3\n",
      "                                  Fishes not identified       0.67      0.40      0.50         5\n",
      "                               Not classified pork meat       0.33      1.00      0.50         1\n",
      "                             Pangas catfishes (generic)       0.00      0.00      0.00         0\n",
      "                    Precooked cooked pork meat products       0.00      0.00      0.00         1\n",
      "                                     after dinner mints       0.00      0.00      0.00         1\n",
      "                                                  algae       0.67      0.67      0.67         3\n",
      "                                        almond products       0.67      1.00      0.80         2\n",
      "                                                almonds       0.50      1.00      0.67         1\n",
      "                                       anchovies in oil       0.00      0.00      0.00         1\n",
      "                                             angus beef       0.00      0.00      0.00         1\n",
      "                                             apple cake       0.00      0.00      0.00         1\n",
      "                                                 apples       0.00      0.00      0.00         0\n",
      "                                               apricots       0.00      0.00      0.00         1\n",
      "                          assorted bread roll selection       0.00      0.00      0.00         0\n",
      "                                              baby food       0.00      0.00      0.00         1\n",
      "                                           baby spinach       0.67      1.00      0.80         2\n",
      "                                        bakery products       0.00      0.00      0.00         1\n",
      "                                             baking mix       0.00      0.00      0.00         1\n",
      "                                                 bamboo       0.00      0.00      0.00         1\n",
      "                                          bamboo shoots       0.00      0.00      0.00         0\n",
      "                                                   bars       0.00      0.00      0.00         1\n",
      "                                      basil pesto sauce       1.00      1.00      1.00         1\n",
      "                                             bean paste       0.00      0.00      0.00         0\n",
      "                                             bean snack       0.00      0.00      0.00         1\n",
      "                                                   beef       0.00      0.00      0.00         3\n",
      "                                          beef products       0.40      1.00      0.57         2\n",
      "                                            beef stewed       0.00      0.00      0.00         1\n",
      "                                                   beer       0.00      0.00      0.00         1\n",
      "                                               beverage       0.00      0.00      0.00         0\n",
      "                                               biscuits       0.00      0.00      0.00         2\n",
      "                                 bitter apricot kernels       0.50      1.00      0.67         1\n",
      "                                           black pepper       0.00      0.00      0.00         0\n",
      "                                            blue cheese       0.00      0.00      0.00         0\n",
      "                    boletus mushrooms, stems and pieces       0.00      0.00      0.00         1\n",
      "                                  bottled mineral water       1.00      1.00      1.00         2\n",
      "                                            brazil nuts       0.33      1.00      0.50         1\n",
      "                                                  bread       0.00      0.00      0.00         2\n",
      "                            bread and products therefor       0.00      0.00      0.00         2\n",
      "                                            bread crumb       0.00      0.00      0.00         0\n",
      "                                      breakfast cereals       0.00      0.00      0.00         0\n",
      "                                               brownies       0.00      0.00      0.00         0\n",
      "                                                   buns       0.00      0.00      0.00         1\n",
      "                                                 butter       0.00      0.00      0.00         0\n",
      "                                                  cakes       0.73      0.89      0.80         9\n",
      "                                                candies       0.00      0.00      0.00         3\n",
      "                                         canned chicken       0.00      0.00      0.00         1\n",
      "                                         canned mussels       0.00      0.00      0.00         1\n",
      "                                         canned spinach       0.00      0.00      0.00         1\n",
      "                                          caramel bites       0.00      0.00      0.00         0\n",
      "                                    carbonated beverage       0.00      0.00      0.00         0\n",
      "                                         cardamom seeds       0.00      0.00      0.00         1\n",
      "                                         cardamon seeds       0.00      0.00      0.00         0\n",
      "                                                 cashew       1.00      1.00      1.00         1\n",
      "                                                cbd oil       1.00      1.00      1.00         1\n",
      "                                                 cereal       0.00      0.00      0.00         1\n",
      "                                            cereal bars       0.00      0.00      0.00         0\n",
      "                                         cheddar cheese       0.00      0.00      0.00         0\n",
      "                                                 cheese       0.43      0.43      0.43         7\n",
      "                                         cheese burgers       0.00      0.00      0.00         1\n",
      "                                        cheese products       0.00      0.00      0.00         1\n",
      "                                             chia seeds       1.00      1.00      1.00         2\n",
      "                                                chicken       0.00      0.00      0.00         3\n",
      "                                 chicken based products       0.54      0.64      0.58        11\n",
      "                                         chicken breast       0.00      0.00      0.00         0\n",
      "                                          chicken broth       0.00      0.00      0.00         1\n",
      "                                        chicken dippers       0.00      0.00      0.00         1\n",
      "                                      chicken meat meal       0.00      0.00      0.00         1\n",
      "                                  chicken meat products       0.00      0.00      0.00         0\n",
      "                                   chicken preparations       0.25      0.33      0.29         3\n",
      "                              chicken products - frozen       0.00      0.00      0.00         0\n",
      "                                        chilled chicken       0.00      0.00      0.00         1\n",
      "                                         chilled salads       0.00      0.00      0.00         4\n",
      "                                           chilli paste       0.00      0.00      0.00         1\n",
      "                                          chilli pickle       0.00      0.00      0.00         0\n",
      "                                           chilli sauce       0.00      0.00      0.00         0\n",
      "                                              chocolate       0.00      0.00      0.00         6\n",
      "                          chocolate and hazelnut spread       0.00      0.00      0.00         2\n",
      "                        chocolate and products therefor       1.00      1.00      1.00         1\n",
      "                                         chocolate bars       0.50      0.75      0.60         4\n",
      "                                        chocolate chips       0.00      0.00      0.00         0\n",
      "                                         chocolate eggs       1.00      1.00      1.00         2\n",
      "                                     chocolate products       0.67      0.67      0.67         3\n",
      "                                       chocolate spread       0.00      0.00      0.00         1\n",
      "                                       chocolate wafers       1.00      1.00      1.00         1\n",
      "                                             chocolates       0.00      0.00      0.00         0\n",
      "                                                chorizo       1.00      0.67      0.80         3\n",
      "                                         cinnamon rolls       0.00      0.00      0.00         0\n",
      "                                          coconut juice       0.50      1.00      0.67         1\n",
      "                                           coconut milk       0.00      0.00      0.00         1\n",
      "                                               coconuts       1.00      1.00      1.00         2\n",
      "                                           coffee beans       0.00      0.00      0.00         1\n",
      "                                           coffee drink       0.00      0.00      0.00         0\n",
      "                                    concentrated apples       0.00      0.00      0.00         0\n",
      "                                          confectionery       0.00      0.00      0.00         0\n",
      "                                         cooked chicken       0.33      1.00      0.50         1\n",
      "                                             cooked ham       0.00      0.00      0.00         0\n",
      "                                                cookies       0.80      0.80      0.80         5\n",
      "                                                   corn       0.33      0.33      0.33         3\n",
      "                                         cottage cheese       0.00      0.00      0.00         1\n",
      "                                              cous cous       0.00      0.00      0.00         1\n",
      "                                        cow milk cheese       0.00      0.00      0.00         1\n",
      "                                                  crabs       0.00      0.00      0.00         0\n",
      "                                               crackers       0.00      0.00      0.00         0\n",
      "                                           cream cheese       0.00      0.00      0.00         1\n",
      "                                                 crisps       0.00      0.00      0.00         1\n",
      "                                             croissants       1.00      1.00      1.00         1\n",
      "                                               cupcakes       0.00      0.00      0.00         1\n",
      "                                             cured loin       0.00      0.00      0.00         1\n",
      "                                        dark chocolates       0.50      0.67      0.57         3\n",
      "                                                  dates       1.00      1.00      1.00         1\n",
      "                                               desserts       1.00      0.50      0.67         2\n",
      "                                       dietary capsules       0.00      0.00      0.00         0\n",
      "                                     dietary supplement       0.33      0.50      0.40         2\n",
      "      dietetic foods, food supplements, fortified foods       0.00      0.00      0.00         1\n",
      "                                              dip-sauce       0.00      0.00      0.00         2\n",
      "                                          dipping sauce       0.00      0.00      0.00         1\n",
      "                                                 donuts       0.00      0.00      0.00         1\n",
      "                                               dressing       0.00      0.00      0.00         0\n",
      "                                        dried anchovies       0.00      0.00      0.00         1\n",
      "                                           dried apples       0.00      0.00      0.00         1\n",
      "                                         dried apricots       1.00      1.00      1.00         3\n",
      "                                        dried beef meat       1.00      1.00      1.00         6\n",
      "                                          dried coconut       1.00      1.00      1.00         1\n",
      "                                      dried cranberries       0.00      0.00      0.00         1\n",
      "                                             dried figs       1.00      1.00      1.00         1\n",
      "                                        dried mushrooms       0.00      0.00      0.00         0\n",
      "                                            dried plums       0.00      0.00      0.00         0\n",
      "                                          dried sausage       0.00      0.00      0.00         0\n",
      "                                            dry sausage       0.00      0.00      0.00         1\n",
      "                                                   duck       0.50      1.00      0.67         1\n",
      "                                              dumplings       0.00      0.00      0.00         1\n",
      "                                            edam cheese       0.00      0.00      0.00         0\n",
      "                                              eggplants       0.00      0.00      0.00         0\n",
      "                                                   eggs       1.00      1.00      1.00         4\n",
      "                                  eggs and egg products       0.00      0.00      0.00         1\n",
      "emulsifiers, stabilizers, thickeners and gelling agents       0.00      0.00      0.00         0\n",
      "                                         feed materials       0.00      0.00      0.00         2\n",
      "                                           fennel seeds       1.00      1.00      1.00         1\n",
      "                                            feta cheese       0.00      0.00      0.00         0\n",
      "                                               fish roe       0.00      0.00      0.00         0\n",
      "                                   flavoured soft drink       0.00      0.00      0.00         1\n",
      "                    flavoured whey protein preparations       1.00      1.00      1.00         1\n",
      "                                                  flour       1.00      0.50      0.67         2\n",
      "                                              foie gras       0.00      0.00      0.00         1\n",
      "                                             fresh beef       0.00      0.00      0.00         1\n",
      "                                        fresh mushrooms       0.50      1.00      0.67         1\n",
      "                                          fresh parsley       0.00      0.00      0.00         1\n",
      "                                        fresh pork loin       0.00      0.00      0.00         0\n",
      "                                       fresh vegetables       0.00      0.00      0.00         1\n",
      "                                            frozen beef       0.00      0.00      0.00         1\n",
      "                                    frozen beef patties       1.00      0.50      0.67         2\n",
      "                                     frozen beef tongue       0.00      0.00      0.00         0\n",
      "                                    frozen bourbon ribs       0.00      0.00      0.00         0\n",
      "                                        frozen broccoli       0.00      0.00      0.00         1\n",
      "                                     frozen burger buns       0.00      0.00      0.00         1\n",
      "                                         frozen burgers       0.00      0.00      0.00         1\n",
      "                                         frozen chicken       0.00      0.00      0.00         1\n",
      "                     frozen chicken strips with tendons       0.00      0.00      0.00         0\n",
      "                                     frozen green beans       0.00      0.00      0.00         1\n",
      "                                            frozen peas       0.00      0.00      0.00         0\n",
      "                                         frozen peppers       0.00      0.00      0.00         1\n",
      "                                           frozen pizza       1.00      0.50      0.67         2\n",
      "                               frozen pork preparations       0.00      0.00      0.00         0\n",
      "                            frozen poultry preparations       0.00      0.00      0.00         1\n",
      "                                frozen poultry products       0.00      0.00      0.00         1\n",
      "                           frozen ready to cook chicken       0.00      0.00      0.00         1\n",
      "                           frozen ready to eat products       0.00      0.00      0.00         0\n",
      "                                      frozen vegetables       0.50      1.00      0.67         1\n",
      "                               frozen vegetarian cutlet       0.00      0.00      0.00         1\n",
      "                                            fruit juice       0.00      0.00      0.00         2\n",
      "                                             fruit pies       0.00      0.00      0.00         0\n",
      "                                            fruit punch       1.00      1.00      1.00         1\n",
      "                                           fruit snacks       0.00      0.00      0.00         0\n",
      "                                  fruits and vegetables       0.00      0.00      0.00         0\n",
      "                                          garlic powder       1.00      1.00      1.00         1\n",
      "                                         ginseng powder       0.00      0.00      0.00         0\n",
      "                                            goat cheese       1.00      1.00      1.00         1\n",
      "                                      gorgonzola cheese       0.00      0.00      0.00         0\n",
      "                                           gouda cheese       0.00      0.00      0.00         1\n",
      "                                                granola       1.00      1.00      1.00         1\n",
      "                                              gravy mix       0.00      0.00      0.00         1\n",
      "                                             green bean       0.00      0.00      0.00         0\n",
      "                                            green pesto       0.00      0.00      0.00         0\n",
      "                                   grissini breadsticks       0.00      0.00      0.00         1\n",
      "                                         ground almonds       0.00      0.00      0.00         1\n",
      "                                            ground beef       0.71      0.83      0.77         6\n",
      "                                       ground beef meat       0.00      0.00      0.00         1\n",
      "                                    ground black pepper       0.00      0.00      0.00         1\n",
      "                                        halloumi cheese       1.00      1.00      1.00         1\n",
      "                                                  halva       0.00      0.00      0.00         1\n",
      "                                                    ham       1.00      0.50      0.67         2\n",
      "                                              hazelnuts       0.00      0.00      0.00         0\n",
      "                                                herring       1.00      0.67      0.80         3\n",
      "                                    horseradish in jars       0.00      0.00      0.00         1\n",
      "                                              ice cream       0.97      0.90      0.93        31\n",
      "                                         infant formula       1.00      1.00      1.00         2\n",
      "                                         instant cereal       0.00      0.00      0.00         1\n",
      "                                         instant coffee       0.50      1.00      0.67         1\n",
      "                                                    jam       0.67      0.67      0.67         3\n",
      "                                                jellies       1.00      1.00      1.00         3\n",
      "                                            juice drink       0.00      0.00      0.00         0\n",
      "                                                   kale       1.00      1.00      1.00         1\n",
      "                                                   lamb       0.00      0.00      0.00         0\n",
      "                                                lasagne       1.00      1.00      1.00         1\n",
      "                                  lemonade (lemon soda)       0.00      0.00      0.00         1\n",
      "                                                lettuce       1.00      1.00      1.00         1\n",
      "                                       liquid egg white       1.00      1.00      1.00         1\n",
      "                                 liquid food supplement       0.00      0.00      0.00         1\n",
      "                                              liquorice       0.00      0.00      0.00         0\n",
      "                                            lupin seeds       0.00      0.00      0.00         1\n",
      "                                               mackerel       0.50      1.00      0.67         1\n",
      "                                                  maize       1.00      0.50      0.67         2\n",
      "                                              margarine       0.00      0.00      0.00         1\n",
      "                                            marshmalows       0.00      0.00      0.00         1\n",
      "                                       masala spice mix       0.00      0.00      0.00         1\n",
      "                              mashed chickpeas (hummus)       0.50      1.00      0.67         1\n",
      "                                  massala spice mixture       0.00      0.00      0.00         0\n",
      "                                             mayonnaise       0.00      0.00      0.00         1\n",
      "            meat and meat products (other than poultry)       0.00      0.00      0.00         1\n",
      "                                              meat loaf       0.00      0.00      0.00         1\n",
      "                                      meat preparations       0.00      0.00      0.00         1\n",
      "                    mechanically separated chicken meat       0.00      0.00      0.00         1\n",
      "                                                   milk       0.33      1.00      0.50         2\n",
      "                         milk chocolate covered raisins       1.00      1.00      1.00         2\n",
      "                                        milk chocolates       0.00      0.00      0.00         1\n",
      "                                            milk powder       0.00      0.00      0.00         0\n",
      "                                          milk products       0.00      0.00      0.00         1\n",
      "                                            minced beef       1.00      1.00      1.00         1\n",
      "                                         mint chocolate       0.00      0.00      0.00         0\n",
      "                            mitragyna speciosa (kratom)       0.67      0.67      0.67         3\n",
      "                                            mix of nuts       0.00      0.00      0.00         1\n",
      "                                       mixed vegetables       0.00      0.00      0.00         1\n",
      "                                               moussaka       0.00      0.00      0.00         1\n",
      "                                      mozzarella cheese       1.00      1.00      1.00         1\n",
      "                                                 muesli       0.25      0.33      0.29         3\n",
      "                                                muffins       0.00      0.00      0.00         0\n",
      "                                              mushrooms       0.00      0.00      0.00         1\n",
      "                                                mussels       0.00      0.00      0.00         0\n",
      "                                                mustard       1.00      1.00      1.00         1\n",
      "                                     non-alcoholic beer       0.00      0.00      0.00         1\n",
      "                                non-alcoholic beverages       0.00      0.00      0.00         1\n",
      "                                                noodles       0.00      0.00      0.00         1\n",
      "                                     nut-almond mixture       0.00      0.00      0.00         1\n",
      "                                                   nuts       0.00      0.00      0.00         1\n",
      "                                               nuts mix       0.00      0.00      0.00         0\n",
      "                                              olive oil       1.00      1.00      1.00         1\n",
      "                                                 olives       1.00      1.00      1.00         2\n",
      "                                                 onions       0.50      0.67      0.57         3\n",
      "                                           orange juice       0.00      0.00      0.00         0\n",
      "                                     orange sugar paste       0.00      0.00      0.00         1\n",
      "                                                oregano       0.00      0.00      0.00         1\n",
      "                                 organic chilled hummus       0.00      0.00      0.00         1\n",
      "                                   other dairy products       0.00      0.00      0.00         2\n",
      "                     other not classified meat products       0.50      0.33      0.40         3\n",
      "                                    other types of meat       1.00      0.50      0.67         2\n",
      "                               other water-based drinks       0.00      0.00      0.00         1\n",
      "                                                oysters       1.00      1.00      1.00         3\n",
      "                                                 paella       1.00      1.00      1.00         1\n",
      "                                               pancakes       1.00      0.50      0.67         2\n",
      "                                                parsley       0.00      0.00      0.00         0\n",
      "                                                  pasta       0.00      0.00      0.00         0\n",
      "                                         pasta products       0.00      0.00      0.00         0\n",
      "                                                 pastry       0.00      0.00      0.00         1\n",
      "                                        pastry products       0.50      0.50      0.50         2\n",
      "                                                peanuts       1.00      0.57      0.73         7\n",
      "                                             pear juice       0.00      0.00      0.00         1\n",
      "                                                  pesto       0.00      0.00      0.00         1\n",
      "                                               pet feed       1.00      1.00      1.00         3\n",
      "                                   pickled grape leaves       1.00      1.00      1.00         1\n",
      "                                        pickled peppers       0.00      0.00      0.00         1\n",
      "                                         pickled radish       0.00      0.00      0.00         0\n",
      "                                        pig meat - pork       0.00      0.00      0.00         1\n",
      "                                              pine nuts       0.00      0.00      0.00         1\n",
      "                                         pistachio nuts       1.00      1.00      1.00         5\n",
      "                                                  pizza       0.50      1.00      0.67         1\n",
      "                                               plastics       1.00      1.00      1.00         1\n",
      "                        plum bread &amp; butter pudding       0.00      0.00      0.00         1\n",
      "                                               pork pie       0.00      0.00      0.00         1\n",
      "                                       pork preparation       0.00      0.00      0.00         0\n",
      "                                           pork sausage       0.67      1.00      0.80         2\n",
      "                                           potato chips       0.50      0.50      0.50         2\n",
      "                                               potatoes       1.00      0.50      0.67         2\n",
      "                                                poultry       0.00      0.00      0.00         0\n",
      "                                                 prawns       0.00      0.00      0.00         0\n",
      "                    precooked cooked beef meat products       1.00      0.50      0.67         2\n",
      "                                        prepacked salad       0.00      0.00      0.00         0\n",
      "                                        prepared salads       0.00      0.00      0.00         3\n",
      "                                          protein balls       1.00      1.00      1.00         1\n",
      "                                            protein bar       1.00      1.00      1.00         1\n",
      "                                          protein drink       1.00      1.00      1.00         1\n",
      "                                         protein powder       0.00      0.00      0.00         1\n",
      "                                                pudding       0.00      0.00      0.00         0\n",
      "                                            puffed rice       0.00      0.00      0.00         1\n",
      "                                                   pâté       0.00      0.00      0.00         1\n",
      "                                            raspberries       1.00      0.50      0.67         2\n",
      "                                          raw beef meat       0.00      0.00      0.00         1\n",
      "                                  raw cow's milk cheese       0.00      0.00      0.00         1\n",
      "                                   raw goat milk cheese       1.00      1.00      1.00         1\n",
      "                                               raw milk       0.00      0.00      0.00         3\n",
      "                              raw milk cheese reblochon       0.00      0.00      0.00         1\n",
      "               ready cooked sliced chicken tikka breast       0.00      0.00      0.00         1\n",
      "                              ready to eat - cook meals       0.11      0.10      0.11        10\n",
      "                                             red chilli       0.00      0.00      0.00         1\n",
      "                                           refreshments       0.00      0.00      0.00         1\n",
      "                                                   rice       0.00      0.00      0.00         1\n",
      "                                          rice crackers       0.00      0.00      0.00         0\n",
      "                                              rice meal       0.00      0.00      0.00         1\n",
      "                                             rice snack       0.00      0.00      0.00         0\n",
      "                                        rice vermicelli       0.00      0.00      0.00         0\n",
      "                                           roasted nuts       0.00      0.00      0.00         0\n",
      "                                         salad dressing       0.00      0.00      0.00         1\n",
      "                                                 salads       0.67      0.67      0.67         6\n",
      "                                                 salami       1.00      1.00      1.00         2\n",
      "                                                 salmon       0.75      0.75      0.75         4\n",
      "                                                   salt       1.00      1.00      1.00         1\n",
      "                                       salted anchovies       0.00      0.00      0.00         0\n",
      "                                             sandwiches       0.83      0.83      0.83         6\n",
      "                                                  sauce       0.00      0.00      0.00         1\n",
      "                                                 sauces       0.00      0.00      0.00         0\n",
      "                                                sausage       0.40      0.40      0.40         5\n",
      "                                                seafood       0.00      0.00      0.00         1\n",
      "                                       seafood products       0.00      0.00      0.00         0\n",
      "                                       seasoned chicken       0.00      0.00      0.00         1\n",
      "                                              seasoning       0.50      1.00      0.67         1\n",
      "                                        seasoning sauce       0.00      0.00      0.00         1\n",
      "                                   seaweed preparations       0.00      0.00      0.00         1\n",
      "                                       semi-soft cheese       0.00      0.00      0.00         0\n",
      "                                             sesame oil       0.00      0.00      0.00         0\n",
      "                                           sesame paste       0.00      0.00      0.00         0\n",
      "                                        sesame seed oil       0.00      0.00      0.00         1\n",
      "                                           sesame seeds       1.00      1.00      1.00         1\n",
      "                                                shrimps       0.67      1.00      0.80         2\n",
      "                                             sliced ham       0.00      0.00      0.00         0\n",
      "                                         smoked sausage       0.50      1.00      0.67         1\n",
      "                                         snack crackers       0.50      1.00      0.67         1\n",
      "                                              snack mix       1.00      0.25      0.40         4\n",
      "                                       snacks (various)       0.33      0.50      0.40         2\n",
      "                                            soft cheese       0.00      0.00      0.00         0\n",
      "                                                   soup       0.43      1.00      0.60         3\n",
      "                                         soy bean paste       0.00      0.00      0.00         1\n",
      "                                             soya drink       0.00      0.00      0.00         0\n",
      "                                    sparkling beverages       0.00      0.00      0.00         0\n",
      "                                          spice mixture       0.00      0.00      0.00         0\n",
      "                                                 spices       0.00      0.00      0.00         1\n",
      "                                            sport drink       1.00      1.00      1.00         1\n",
      "                                           spring rolls       1.00      1.00      1.00         2\n",
      "                                           spring water       1.00      1.00      1.00         1\n",
      "                                                  squid       0.00      0.00      0.00         0\n",
      "                                                  sugar       0.50      1.00      0.67         1\n",
      "                                         sunflower seed       0.67      0.80      0.73         5\n",
      "                                                 sweets       0.00      0.00      0.00         1\n",
      "                                             taco sauce       0.00      0.00      0.00         1\n",
      "                                                 tahini       1.00      0.60      0.75         5\n",
      "                                  tahini (sesame paste)       0.00      0.00      0.00         1\n",
      "                                                    tea       0.00      0.00      0.00         0\n",
      "                                               tea bags       0.00      0.00      0.00         1\n",
      "                                              tea drink       0.00      0.00      0.00         1\n",
      "                            thermal processed beef meat       0.00      0.00      0.00         2\n",
      "                            thermal processed pork meat       0.50      0.50      0.50         2\n",
      "                                           tomato sauce       0.00      0.00      0.00         0\n",
      "                                                 trouts       0.00      0.00      0.00         0\n",
      "                                                   tuna       1.00      1.00      1.00         3\n",
      "                         turkey and turkey preparations       1.00      1.00      1.00         1\n",
      "                                  turkey based products       0.00      0.00      0.00         2\n",
      "                                        turkey sandwich       0.00      0.00      0.00         0\n",
      "                                         tzatziki sauce       0.00      0.00      0.00         1\n",
      "                                various bakery products       0.00      0.00      0.00         1\n",
      "                                        various cheeses       0.00      0.00      0.00         0\n",
      "                                 various pasta products       0.00      0.00      0.00         1\n",
      "                                   various poultry meat       0.00      0.00      0.00         0\n",
      "                                various prepared dishes       0.00      0.00      0.00         0\n",
      "                               vegetable based products       0.00      0.00      0.00         1\n",
      "                                             vegetables       0.00      0.00      0.00         1\n",
      "                                                waffles       0.67      1.00      0.80         2\n",
      "                                                walnuts       1.00      1.00      1.00         1\n",
      "                                           whey protein       1.00      1.00      1.00         1\n",
      "                                    white lasagna sauce       1.00      1.00      1.00         1\n",
      "                                                   wine       1.00      1.00      1.00         1\n",
      "                                                  wraps       1.00      0.50      0.67         2\n",
      "                                                yoghurt       0.75      1.00      0.86         3\n",
      "                                         yogurt raisins       0.00      0.00      0.00         0\n",
      "\n",
      "                                               accuracy                           0.49       509\n",
      "                                              macro avg       0.27      0.29      0.27       509\n",
      "                                           weighted avg       0.50      0.49      0.48       509\n",
      "\n",
      "Label Encoder for product saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_and_evaluate_bert(data_splits, targets):\n",
    "    f1_scores = []\n",
    "\n",
    "    for target in targets:\n",
    "        print(f\"\\nStarting training for task: {target}\")\n",
    "\n",
    "        # Retrieve training and testing data\n",
    "        X_train, X_test, y_train, y_test = data_splits[target]\n",
    "        texts_train = X_train['text'].values\n",
    "        texts_test = X_test['text'].values\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = TextDataset(texts_train, y_train, tokenizer, config['max_len'])\n",
    "        test_dataset = TextDataset(texts_test, y_test, tokenizer, config['max_len'])\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "        num_classes = len(label_encoders[target].classes_)\n",
    "\n",
    "        # Load the model\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(config['model_name'], num_labels=num_classes).to(device)\n",
    "\n",
    "        # Use AdamW optimizer\n",
    "        optimizer = AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=0.01)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=3, verbose=True)\n",
    "        criterion = nn.CrossEntropyLoss()  # Without class weights\n",
    "\n",
    "        # Early stopping setup\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        patience = 6\n",
    "        epochs_without_improvement = 0\n",
    "        best_model = None\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(config['epochs']):\n",
    "            print(f\"Epoch {epoch+1}/{config['epochs']} - Training: {target}\")\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", total=len(train_loader), leave=True)\n",
    "            epoch_loss = 0.0\n",
    "            total_batches = 0\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs.logits, labels)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                total_batches += 1\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / total_batches\n",
    "            print(f\"Average Loss after Epoch {epoch+1}: {avg_epoch_loss}\")\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"Learning rate after epoch {epoch+1}: {current_lr}\")\n",
    "            scheduler.step(avg_epoch_loss)\n",
    "\n",
    "            if avg_epoch_loss < best_val_loss:\n",
    "                best_val_loss = avg_epoch_loss\n",
    "                best_epoch = epoch + 1\n",
    "                epochs_without_improvement = 0\n",
    "                best_model = model.state_dict()\n",
    "                print(f\"New best model found. Saving at epoch {best_epoch}.\")\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                if epochs_without_improvement >= patience:\n",
    "                    print(\"Early stopping triggered!\")\n",
    "                    break\n",
    "\n",
    "        # Save the best model\n",
    "        if best_model:\n",
    "            print(f\"Saving the best model from epoch {best_epoch}.\")\n",
    "            model.load_state_dict(best_model)\n",
    "            model.save_pretrained(f'./best_model_{target}')\n",
    "            tokenizer.save_pretrained(f'./best_model_{target}')\n",
    "        else:\n",
    "            print(\"No improvement in training loss. No model saved.\")\n",
    "\n",
    "        # Evaluation\n",
    "        print(f\"Evaluating model for task: {target}\")\n",
    "        model.eval()\n",
    "        y_preds = []\n",
    "        y_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Evaluating\", total=len(test_loader), leave=True):\n",
    "                input_ids = batch['input_ids'].squeeze(1).to(device)\n",
    "                attention_mask = batch['attention_mask'].squeeze(1).to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                _, preds = torch.max(outputs.logits, dim=1)\n",
    "                y_preds.extend(preds.cpu().numpy())\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Decode and calculate F1\n",
    "        decoded_preds = label_encoders[target].inverse_transform(y_preds)\n",
    "        decoded_true = label_encoders[target].inverse_transform(y_true)\n",
    "        f1 = f1_score(decoded_true, decoded_preds, average='macro')\n",
    "        f1_scores.append(f1)\n",
    "        print(f\"F1-Score for {target}: {f1}\")\n",
    "        print(classification_report(decoded_true, decoded_preds, zero_division=0))\n",
    "\n",
    "        np.save(f'./best_model_{target}/{target}_label_encoder.npy', label_encoders[target].classes_)\n",
    "        print(f\"Label Encoder for {target} saved.\")\n",
    "\n",
    "    return f1_scores\n",
    "\n",
    "# Train and evaluate for all targets\n",
    "text_f1_scores = train_and_evaluate_bert(text_splits, targets_subtask1 + targets_subtask2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLUojbN91Oon"
   },
   "source": [
    "# Generate predictions on the test data and print the predictions DataFrame\n",
    "Here, we load the test dataset, use the trained model to generate predictions, and display the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1asDnwc-1QIb",
    "outputId": "94f46756-c784-4b8d-e2e9-00f80807bbdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Final Predictions:\n",
      "\n",
      "    hazard-category                                   product-category  \\\n",
      "0        biological                       meat, egg and dairy products   \n",
      "1        biological                       meat, egg and dairy products   \n",
      "2        biological                       meat, egg and dairy products   \n",
      "3         allergens                                  ices and desserts   \n",
      "4    foreign bodies                       meat, egg and dairy products   \n",
      "..              ...                                                ...   \n",
      "560       allergens                              fruits and vegetables   \n",
      "561       allergens  dietetic foods, food supplements, fortified foods   \n",
      "562  foreign bodies                        cereals and bakery products   \n",
      "563       allergens                        cereals and bakery products   \n",
      "564       allergens                                      confectionery   \n",
      "\n",
      "                           hazard                      product  \n",
      "0          listeria monocytogenes                   cooked ham  \n",
      "1                escherichia coli                       salami  \n",
      "2                   enteroviruses               cooked chicken  \n",
      "3                       pecan nut                    ice cream  \n",
      "4                  metal fragment       chicken based products  \n",
      "..                            ...                          ...  \n",
      "560                        cashew              long grain rice  \n",
      "561     milk and products thereof                  protein bar  \n",
      "562              plastic fragment                      cookies  \n",
      "563  peanuts and products thereof                     biscuits  \n",
      "564                        almond  dried fruits with chocolate  \n",
      "\n",
      "[565 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the test data for predictions (CSV containing validation data)\n",
    "test_path = '/content/drive/MyDrive/Data/validation_data/incidents.csv'\n",
    "test_df = pd.read_csv(test_path, index_col=0)\n",
    "\n",
    "# Define the predict function\n",
    "def predict(texts, model_base_path, target):\n",
    "    # Load the tokenizer for the specified pre-trained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_base_path)\n",
    "\n",
    "    # Load the correct label encoder for the given target\n",
    "    label_encoder_path = f'{model_base_path}/{target}_label_encoder.npy'\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Check if the label encoder file exists and load it\n",
    "    if os.path.exists(label_encoder_path):\n",
    "        label_encoder.classes_ = np.load(label_encoder_path, allow_pickle=True)\n",
    "    else:\n",
    "        # Print a warning if the label encoder is not found\n",
    "        print(f\"Warning: Label encoder not found for {target} at {label_encoder_path}\")\n",
    "        return None\n",
    "\n",
    "    # Load the pre-trained model for sequence classification\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_base_path).to(device)\n",
    "\n",
    "    # Tokenize the input texts\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,  # Pad sequences to the max length\n",
    "        truncation=True,  # Truncate sequences to the max length\n",
    "        max_length=512,  # Limit sequence length to 512 tokens\n",
    "        return_tensors=\"pt\"  # Return PyTorch tensors\n",
    "    ).to(device)\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Make predictions with no gradient calculation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)  # Get the predicted class for each input\n",
    "\n",
    "    # Decode the predictions using the label encoder\n",
    "    decoded_predictions = label_encoder.inverse_transform(predictions.cpu().numpy())\n",
    "\n",
    "    # Return the decoded predictions\n",
    "    return decoded_predictions\n",
    "\n",
    "# Define device for model prediction (use GPU if available, else use CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare an empty dataframe to store the predictions\n",
    "predictions = pd.DataFrame()\n",
    "\n",
    "# Run predictions for all targets using the correct saved model\n",
    "for column in targets_subtask1 + targets_subtask2:\n",
    "    # Define the model path dynamically based on the target column\n",
    "    model_path = f'./best_model_{column}'  # Update model path to point to the best model\n",
    "\n",
    "    # Get the decoded predictions for the current target\n",
    "    decoded_preds = predict(test_df['text'].tolist(), model_path, column)\n",
    "\n",
    "    # If predictions were successfully made, store them in the dataframe\n",
    "    if decoded_preds is not None:\n",
    "        predictions[column] = decoded_preds\n",
    "\n",
    "# Display the final predictions\n",
    "print(\"\\nFinal Predictions:\\n\")\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6gfxEZFM2Kq"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5p7qVnA0Gc4"
   },
   "source": [
    "# Create the submission folder and archive the results\n",
    "Finally, predictions and models are saved into a submission directory for easy sharing or evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REr-ySES0FHE",
    "outputId": "5de5b297-6a9f-4b23-bd71-a58a81ad8ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to Google Drive at /content/drive/MyDrive/submission_finetuned_SciBERT/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import make_archive\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "\n",
    "# Define the Google Drive path where you want to save the files\n",
    "output_folder = '/content/drive/MyDrive/submission_finetuned_SciBERT/'\n",
    "\n",
    "# Create the folder in Google Drive if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save predictions to a CSV file named 'submission.csv' inside the folder\n",
    "predictions.to_csv(f'{output_folder}submission.csv', index=False)\n",
    "\n",
    "# Zip the folder for submission\n",
    "make_archive(output_folder, 'zip', output_folder)\n",
    "\n",
    "# Print confirmation message\n",
    "print(f\"Submission saved to Google Drive at {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iNRwL3hTarL-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
