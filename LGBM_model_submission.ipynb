{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Shape': (5082, 11), 'Columns': ['Unnamed: 0', 'year', 'month', 'day', 'country', 'title', 'text', 'hazard-category', 'product-category', 'hazard', 'product'], 'df Types': Unnamed: 0           int64\n",
      "year                 int64\n",
      "month                int64\n",
      "day                  int64\n",
      "country             object\n",
      "title               object\n",
      "text                object\n",
      "hazard-category     object\n",
      "product-category    object\n",
      "hazard              object\n",
      "product             object\n",
      "dtype: object, 'Missing Values': Unnamed: 0          0\n",
      "year                0\n",
      "month               0\n",
      "day                 0\n",
      "country             0\n",
      "title               0\n",
      "text                0\n",
      "hazard-category     0\n",
      "product-category    0\n",
      "hazard              0\n",
      "product             0\n",
      "dtype: int64}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\steli\\OneDrive\\Desktop\\Stelios\\DSAUEB\\Trimester 1\\PDS\\A2\\PDS-A2\\Data\\incidents_train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Initial inspection of the data\n",
    "data_overview = {\n",
    "    'Shape': df.shape,\n",
    "    'Columns': df.columns.tolist(),\n",
    "    'df Types': df.dtypes,\n",
    "    'Missing Values': df.isnull().sum(),\n",
    "}\n",
    "\n",
    "print(data_overview)\n",
    "# Drop the unnecessary index column\n",
    "df = df.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting for hazard-category...\n",
      "Training and predicting for product-category...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from shutil import make_archive\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords from nltk (if you haven't already)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean text (title or text) and remove stopwords\n",
    "def clean_text(text):\n",
    "    # Remove non-alphanumeric characters (excluding spaces)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Load test data\n",
    "test_path = r\"C:\\Users\\steli\\OneDrive\\Desktop\\Stelios\\DSAUEB\\Trimester 1\\PDS\\A2\\PDS-A2\\Data\\validation_data\\incidents.csv\"\n",
    "test_df = pd.read_csv(test_path, index_col=0)\n",
    "\n",
    "# Clean the 'text' column\n",
    "test_df['text'] = test_df['text'].apply(clean_text)\n",
    "\n",
    "# Define relevant features and targets\n",
    "features = ['year', 'month', 'day', 'country']\n",
    "targets_subtask1 = ['hazard-category', 'product-category']\n",
    "targets_subtask2 = ['hazard', 'product']\n",
    "all_targets = targets_subtask1 + targets_subtask2\n",
    "\n",
    "# Prepare data function for test set\n",
    "def prepare_test_data(text_column):\n",
    "    X = test_df[features + [text_column]]  # Include cleaned text for prediction\n",
    "    return X\n",
    "\n",
    "# Define LightGBM pipeline for text\n",
    "def build_lgb_pipeline_text():\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(), 'text'),  # Use TF-IDF for text\n",
    "            ('num', StandardScaler(), ['year', 'month', 'day']),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), ['country'])\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # LightGBM classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', lgb.LGBMClassifier(num_leaves=31, learning_rate=0.05, n_estimators=100, verbose=-1))\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# Train a model for each target\n",
    "def train_lgb_model_for_target(target):\n",
    "    text_pipeline = build_lgb_pipeline_text()\n",
    "    \n",
    "    # Split the data for training (use only the current target for y_train)\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df[features + ['text']],  # Features\n",
    "        df[target],  # Target for this specific task\n",
    "        test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    text_pipeline.fit(X_train, y_train)\n",
    "    return text_pipeline\n",
    "\n",
    "# Make predictions on the test data\n",
    "def make_predictions_for_target(pipeline, X_test):\n",
    "    return pipeline.predict(X_test)\n",
    "\n",
    "# Prepare test data\n",
    "test_X = prepare_test_data('text')\n",
    "\n",
    "# Initialize a DataFrame to store all predictions\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "# Train models and make predictions for each target\n",
    "for target in all_targets:\n",
    "    print(f\"Training and predicting for {target}...\")\n",
    "    \n",
    "    # Train a separate model for each target\n",
    "    target_pipeline = train_lgb_model_for_target(target)\n",
    "    \n",
    "    # Make predictions for the test set\n",
    "    predictions_df[target] = make_predictions_for_target(target_pipeline, test_X)\n",
    "\n",
    "# Step 2: Save predictions to a new folder\n",
    "os.makedirs('./submission/', exist_ok=True)\n",
    "predictions_df.to_csv('./submission/submission.csv', index=False)\n",
    "\n",
    "# Step 3: Zip the folder for submission\n",
    "make_archive('./submission', 'zip', './submission')\n",
    "\n",
    "print(\"Predictions and submission.zip created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hazard-category</th>\n",
       "      <th>product-category</th>\n",
       "      <th>hazard</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria spp</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria spp</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>salmonella</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allergens</td>\n",
       "      <td>nuts, nut products and seeds</td>\n",
       "      <td>peanuts and products thereof</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>escherichia coli</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>allergens</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>cereals containing gluten and products thereof</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>allergens</td>\n",
       "      <td>dietetic foods, food supplements, fortified foods</td>\n",
       "      <td>milk and products thereof</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>foreign bodies</td>\n",
       "      <td>cereals and bakery products</td>\n",
       "      <td>plastic fragment</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>allergens</td>\n",
       "      <td>cereals and bakery products</td>\n",
       "      <td>peanuts and products thereof</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>allergens</td>\n",
       "      <td>confectionery</td>\n",
       "      <td>almond</td>\n",
       "      <td>cheese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>565 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hazard-category                                   product-category  \\\n",
       "0        biological                       meat, egg and dairy products   \n",
       "1        biological                       meat, egg and dairy products   \n",
       "2        biological                       meat, egg and dairy products   \n",
       "3         allergens                       nuts, nut products and seeds   \n",
       "4        biological                       meat, egg and dairy products   \n",
       "..              ...                                                ...   \n",
       "560       allergens                              fruits and vegetables   \n",
       "561       allergens  dietetic foods, food supplements, fortified foods   \n",
       "562  foreign bodies                        cereals and bakery products   \n",
       "563       allergens                        cereals and bakery products   \n",
       "564       allergens                                      confectionery   \n",
       "\n",
       "                                             hazard product  \n",
       "0                                      listeria spp  cheese  \n",
       "1                                      listeria spp  cheese  \n",
       "2                                        salmonella  cheese  \n",
       "3                      peanuts and products thereof  cheese  \n",
       "4                                  escherichia coli  cheese  \n",
       "..                                              ...     ...  \n",
       "560  cereals containing gluten and products thereof  cheese  \n",
       "561                       milk and products thereof  cheese  \n",
       "562                                plastic fragment  cheese  \n",
       "563                    peanuts and products thereof  cheese  \n",
       "564                                          almond  cheese  \n",
       "\n",
       "[565 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
